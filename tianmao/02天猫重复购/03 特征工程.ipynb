{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工具导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import gc\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据集\n",
    "\n",
    "#test_data = pd.read_csv('./data_format1/test_format1.csv')\n",
    "#train_data = pd.read_csv('./data_format1/train_format1.csv')\n",
    "\n",
    "#user_info = pd.read_csv('./data_format1/user_info_format1.csv')\n",
    "#user_log = pd.read_csv('./data_format1/user_log_format1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据资源查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name, num_rows):\n",
    "    return pd.read_csv(file_name, nrows=num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内存压缩方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage befor optimization is :{:.2f} MB'.format(start_mem))\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据进行内存压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage befor optimization is :5.97 MB\n",
      "Memory usage after optimization is: 1.74 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage befor optimization is :5.98 MB\n",
      "Memory usage after optimization is: 3.49 MB\n",
      "Decreased by 41.7%\n",
      "Memory usage befor optimization is :9.71 MB\n",
      "Memory usage after optimization is: 3.24 MB\n",
      "Decreased by 66.7%\n",
      "Memory usage befor optimization is :2933.33 MB\n",
      "Memory usage after optimization is: 890.48 MB\n",
      "Decreased by 69.6%\n"
     ]
    }
   ],
   "source": [
    "num_rows = None\n",
    "#num_rows = 2000  # 1000条测试代码使用\n",
    "\n",
    "train_file = './data_format1/train_format1.csv'\n",
    "test_file = './data_format1/test_format1.csv'\n",
    "\n",
    "user_info_file = './data_format1/user_info_format1.csv'\n",
    "user_log_file = './data_format1/user_log_format1.csv'\n",
    "\n",
    "train_data = reduce_mem_usage(read_csv(train_file, num_rows))\n",
    "test_data = reduce_mem_usage(read_csv(test_file, num_rows))\n",
    "\n",
    "user_info = reduce_mem_usage(read_csv(user_info_file, num_rows))\n",
    "user_log = reduce_mem_usage(read_csv(user_log_file, num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>action_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328862</td>\n",
       "      <td>323294</td>\n",
       "      <td>833</td>\n",
       "      <td>2882</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328862</td>\n",
       "      <td>844400</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328862</td>\n",
       "      <td>575153</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>328862</td>\n",
       "      <td>996875</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328862</td>\n",
       "      <td>1086186</td>\n",
       "      <td>1271</td>\n",
       "      <td>1253</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  cat_id  seller_id  brand_id  time_stamp  action_type\n",
       "0   328862   323294     833       2882    2660.0         829            0\n",
       "1   328862   844400    1271       2882    2660.0         829            0\n",
       "2   328862   575153    1271       2882    2660.0         829            0\n",
       "3   328862   996875    1271       2882    2660.0         829            0\n",
       "4   328862  1086186    1271       1253    1049.0         829            0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260864 entries, 0 to 260863\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype\n",
      "---  ------       --------------   -----\n",
      " 0   user_id      260864 non-null  int32\n",
      " 1   merchant_id  260864 non-null  int16\n",
      " 2   label        260864 non-null  int8 \n",
      "dtypes: int16(1), int32(1), int8(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261477 entries, 0 to 261476\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   user_id      261477 non-null  int32  \n",
      " 1   merchant_id  261477 non-null  int16  \n",
      " 2   prob         0 non-null       float64\n",
      "dtypes: float64(1), int16(1), int32(1)\n",
      "memory usage: 3.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424170 entries, 0 to 424169\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    424170 non-null  int32  \n",
      " 1   age_range  421953 non-null  float16\n",
      " 2   gender     417734 non-null  float16\n",
      "dtypes: float16(2), int32(1)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "user_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54925330 entries, 0 to 54925329\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   user_id      int32  \n",
      " 1   item_id      int32  \n",
      " 2   cat_id       int16  \n",
      " 3   seller_id    int16  \n",
      " 4   brand_id     float16\n",
      " 5   time_stamp   int16  \n",
      " 6   action_type  int8   \n",
      "dtypes: float16(1), int16(3), int32(2), int8(1)\n",
      "memory usage: 890.5 MB\n"
     ]
    }
   ],
   "source": [
    "user_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "\n",
    "### 合并用户信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = train_data.append(test_data)\n",
    "all_data = all_data.merge(user_info,on=['user_id'],how='left')\n",
    "del train_data, test_data, user_info\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender\n",
       "0    34176         3906    0.0   NaN        6.0     0.0\n",
       "1    34176          121    0.0   NaN        6.0     0.0\n",
       "2    34176         4356    1.0   NaN        6.0     0.0\n",
       "3    34176         2217    0.0   NaN        6.0     0.0\n",
       "4   230784         4818    0.0   NaN        0.0     0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户行为日志信息按时间进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "按时间排序\n",
    "\"\"\"\n",
    "user_log = user_log.sort_values(['user_id','time_stamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对每个用户的逐个合并所有的item_id, cat_id,seller_id,brand_id,time_stamp, action_type字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "合并数据\n",
    "\"\"\"\n",
    "list_join_func = lambda x: \" \".join([str(i) for i in x])\n",
    "\n",
    "\n",
    "agg_dict = {\n",
    "            'item_id' : list_join_func,\t\n",
    "            'cat_id' : list_join_func,\n",
    "            'seller_id' : list_join_func,\n",
    "            'brand_id' : list_join_func,\n",
    "            'time_stamp' : list_join_func,\n",
    "            'action_type' : list_join_func\n",
    "        }\n",
    "\n",
    "rename_dict = {\n",
    "            'item_id' : 'item_path',\n",
    "            'cat_id' : 'cat_path',\n",
    "            'seller_id' : 'seller_path',\n",
    "            'brand_id' : 'brand_path',\n",
    "            'time_stamp' : 'time_stamp_path',\n",
    "            'action_type' : 'action_type_path'\n",
    "        }\n",
    "\n",
    "def merge_list(df_ID, join_columns, df_data, agg_dict, rename_dict):\n",
    "    df_data = df_data.\\\n",
    "            groupby(join_columns).\\\n",
    "            agg(agg_dict).\\\n",
    "            reset_index().\\\n",
    "            rename(columns=rename_dict)\n",
    "\n",
    "    df_ID = df_ID.merge(df_data, on=join_columns, how=\"left\")\n",
    "    return df_ID\n",
    "\n",
    "all_data = merge_list(all_data, 'user_id', user_log, agg_dict, rename_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>time_stamp_path</th>\n",
       "      <th>action_type_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581818 879005 581818 581818 1011673 52343 2773...</td>\n",
       "      <td>1505 662 1505 1505 1505 662 1095 1505 662 1095...</td>\n",
       "      <td>416 3606 416 416 416 3760 3606 416 1926 3004 4...</td>\n",
       "      <td>4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...</td>\n",
       "      <td>521 521 521 521 521 521 521 521 521 521 521 52...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191923 191923 191923 191923 964906 229470 2294...</td>\n",
       "      <td>1023 1023 1023 1023 662 664 664 1544 664 662 6...</td>\n",
       "      <td>3545 3545 3545 3545 4566 2537 2537 2420 2537 4...</td>\n",
       "      <td>5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...</td>\n",
       "      <td>601 601 601 601 614 614 614 614 614 614 618 61...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  prob  age_range  gender  \\\n",
       "0    34176         3906    0.0   NaN        6.0     0.0   \n",
       "1    34176          121    0.0   NaN        6.0     0.0   \n",
       "2    34176         4356    1.0   NaN        6.0     0.0   \n",
       "3    34176         2217    0.0   NaN        6.0     0.0   \n",
       "4   230784         4818    0.0   NaN        0.0     0.0   \n",
       "\n",
       "                                           item_path  \\\n",
       "0  581818 879005 581818 581818 1011673 52343 2773...   \n",
       "1  581818 879005 581818 581818 1011673 52343 2773...   \n",
       "2  581818 879005 581818 581818 1011673 52343 2773...   \n",
       "3  581818 879005 581818 581818 1011673 52343 2773...   \n",
       "4  191923 191923 191923 191923 964906 229470 2294...   \n",
       "\n",
       "                                            cat_path  \\\n",
       "0  1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n",
       "1  1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n",
       "2  1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n",
       "3  1505 662 1505 1505 1505 662 1095 1505 662 1095...   \n",
       "4  1023 1023 1023 1023 662 664 664 1544 664 662 6...   \n",
       "\n",
       "                                         seller_path  \\\n",
       "0  416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n",
       "1  416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n",
       "2  416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n",
       "3  416 3606 416 416 416 3760 3606 416 1926 3004 4...   \n",
       "4  3545 3545 3545 3545 4566 2537 2537 2420 2537 4...   \n",
       "\n",
       "                                          brand_path  \\\n",
       "0  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n",
       "1  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n",
       "2  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n",
       "3  4014.0 33.0 4014.0 4014.0 4014.0 3738.0 33.0 4...   \n",
       "4  5860.0 5860.0 5860.0 5860.0 6320.0 6064.0 6064...   \n",
       "\n",
       "                                     time_stamp_path  \\\n",
       "0  521 521 521 521 521 521 521 521 521 521 521 52...   \n",
       "1  521 521 521 521 521 521 521 521 521 521 521 52...   \n",
       "2  521 521 521 521 521 521 521 521 521 521 521 52...   \n",
       "3  521 521 521 521 521 521 521 521 521 521 521 52...   \n",
       "4  601 601 601 601 614 614 614 614 614 614 618 61...   \n",
       "\n",
       "                                    action_type_path  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 ...  \n",
       "4  0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除数据并回收内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "删除不需要的数据\n",
    "\"\"\"\n",
    "del user_log\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据统计函数\n",
    "\n",
    "### 统计数据的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_(x):\n",
    "    try:\n",
    "        return len(x.split(' '))\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计唯一数据总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nunique_(x):\n",
    "    try:\n",
    "        return len(set(x.split(' ')))\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计数据最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_(x):\n",
    "    try:\n",
    "        return np.max([int(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计数据最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_(x):\n",
    "    try:\n",
    "        return np.min([int(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计数据的标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_(x):\n",
    "    try:\n",
    "        return np.std([float(i) for i in x.split(' ')])\n",
    "    except:\n",
    "        return -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计数据中top N的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_n(x, n):\n",
    "    try:\n",
    "        return Counter(x.split(' ')).most_common(n)[n-1][0]\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计数据中top N数据的总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_n_cnt(x, n):\n",
    "    try:\n",
    "        return Counter(x.split(' ')).most_common(n)[n-1][1]\n",
    "    except:\n",
    "        return -1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def user_cnt(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(cnt_)\n",
    "    return df_data\n",
    "\n",
    "def user_nunique(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(nunique_)\n",
    "    return df_data\n",
    "    \n",
    "def user_max(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(max_)\n",
    "    return df_data\n",
    "\n",
    "def user_min(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(min_)\n",
    "    return df_data\n",
    "    \n",
    "def user_std(df_data, single_col, name):\n",
    "    df_data[name] = df_data[single_col].apply(std_)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data\n",
    "\n",
    "def user_most_n_cnt(df_data, single_col, name, n=1):\n",
    "    func = lambda x: most_n_cnt(x, n)\n",
    "    df_data[name] = df_data[single_col].apply(func)\n",
    "    return df_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取商铺的基本统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\t提取基本统计特征\n",
    "\"\"\"\n",
    "all_data_test = all_data.head(2000)\n",
    "#all_data_test = all_data\n",
    "# 统计用户 点击、浏览、加购、购买行为\n",
    "# 总次数\n",
    "all_data_test = user_cnt(all_data_test,  'seller_path', 'user_cnt')\n",
    "# 不同店铺个数\n",
    "all_data_test = user_nunique(all_data_test,  'seller_path', 'seller_nunique')\n",
    "# 不同品类个数\n",
    "all_data_test = user_nunique(all_data_test,  'cat_path', 'cat_nunique')\n",
    "# 不同品牌个数\n",
    "all_data_test = user_nunique(all_data_test,  'brand_path', 'brand_nunique')\n",
    "# 不同商品个数\n",
    "all_data_test = user_nunique(all_data_test,  'item_path', 'item_nunique')\n",
    "# 活跃天数\n",
    "all_data_test = user_nunique(all_data_test,  'time_stamp_path', 'time_stamp_nunique')\n",
    "# 不同行为种数\n",
    "all_data_test = user_nunique(all_data_test,  'action_type_path', 'action_type_nunique')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最晚时间\n",
    "all_data_test = user_max(all_data_test,  'action_type_path', 'time_stamp_max')\n",
    "# 最早时间\n",
    "all_data_test = user_min(all_data_test,  'action_type_path', 'time_stamp_min')\n",
    "# 活跃天数方差\n",
    "all_data_test = user_std(all_data_test,  'action_type_path', 'time_stamp_std')\n",
    "# 最早和最晚相差天数\n",
    "all_data_test['time_stamp_range'] = all_data_test['time_stamp_max'] - all_data_test['time_stamp_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户最喜欢的店铺\n",
    "all_data_test = user_most_n(all_data_test, 'seller_path', 'seller_most_1', n=1)\n",
    "# 最喜欢的类目\n",
    "all_data_test = user_most_n(all_data_test, 'cat_path', 'cat_most_1', n=1)\n",
    "# 最喜欢的品牌\n",
    "all_data_test = user_most_n(all_data_test, 'brand_path', 'brand_most_1', n=1)\n",
    "# 最常见的行为动作\n",
    "all_data_test = user_most_n(all_data_test, 'action_type_path', 'action_type_1', n=1)\n",
    "# ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 27)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户最喜欢的店铺 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'seller_path', 'seller_most_1_cnt', n=1)\n",
    "# 最喜欢的类目 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'cat_path', 'cat_most_1_cnt', n=1)\n",
    "# 最喜欢的品牌 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'brand_path', 'brand_most_1_cnt', n=1)\n",
    "# 最常见的行为动作 行为次数\n",
    "all_data_test = user_most_n_cnt(all_data_test, 'action_type_path', 'action_type_1_cnt', n=1)\n",
    "# ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 31)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分开统计用户的点击，加购，购买，收藏特征\n",
    "\n",
    "### 不同行为的业务函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点击、加购、购买、收藏 分开统计\n",
    "\"\"\"\n",
    "统计基本特征函数\n",
    "-- 知识点二\n",
    "-- 根据不同行为的业务函数\n",
    "-- 提取不同特征\n",
    "\"\"\"\n",
    "def col_cnt_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type != None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "                    data_out.append(data_txt)\n",
    "\n",
    "        return len(data_out)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def col_nuique_(df_data, columns_list, action_type):\n",
    "    try:\n",
    "        data_dict = {}\n",
    "\n",
    "        col_list = copy.deepcopy(columns_list)\n",
    "        if action_type != None:\n",
    "            col_list += ['action_type_path']\n",
    "\n",
    "        for col in col_list:\n",
    "            data_dict[col] = df_data[col].split(' ')\n",
    "\n",
    "        path_len = len(data_dict[col])\n",
    "\n",
    "        data_out = []\n",
    "        for i_ in range(path_len):\n",
    "            data_txt = ''\n",
    "            for col_ in columns_list:\n",
    "                if data_dict['action_type_path'][i_] == action_type:\n",
    "                    data_txt += '_' + data_dict[col_][i_]\n",
    "                    data_out.append(data_txt)\n",
    "        return len(set(data_out))\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def user_col_cnt(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_cnt_(x, columns_list, action_type), axis=1)\n",
    "    return df_data\n",
    "\n",
    "def user_col_nunique(df_data, columns_list, action_type, name):\n",
    "    df_data[name] = df_data.apply(lambda x: col_nuique_(x, columns_list, action_type), axis=1)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计店铺被用户点击次数，加购次数，购买次数，收藏次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点击次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '0', 'user_cnt_0')\n",
    "# 加购次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '1', 'user_cnt_1')\n",
    "# 购买次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '2', 'user_cnt_2')\n",
    "# 收藏次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path'], '3', 'user_cnt_3')\n",
    "\n",
    "\n",
    "# # 不同店铺个数\n",
    "all_data_test = user_col_nunique(all_data_test,  ['seller_path'], '0', 'seller_nunique_0')\n",
    "# ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 36)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = all_data_test[all_data_test.user_id==34176].action_type_path[0].split(' ')\n",
    "d = [i for i in arr if i =='3']\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_cnt_0</th>\n",
       "      <th>user_cnt_1</th>\n",
       "      <th>user_cnt_2</th>\n",
       "      <th>user_cnt_3</th>\n",
       "      <th>seller_nunique_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>220293</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>155013</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>24453</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>155781</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>90501</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  user_cnt_0  user_cnt_1  user_cnt_2  user_cnt_3  \\\n",
       "0       34176         410           0          34           7   \n",
       "1       34176         410           0          34           7   \n",
       "2       34176         410           0          34           7   \n",
       "3       34176         410           0          34           7   \n",
       "4      230784          47           0           7           0   \n",
       "...       ...         ...         ...         ...         ...   \n",
       "1995   220293          41           0           2           2   \n",
       "1996   155013         104           0           1           1   \n",
       "1997    24453          69           0          12           0   \n",
       "1998   155781          55           0           4           0   \n",
       "1999    90501          40           0          12          23   \n",
       "\n",
       "      seller_nunique_0  \n",
       "0                  106  \n",
       "1                  106  \n",
       "2                  106  \n",
       "3                  106  \n",
       "4                   20  \n",
       "...                ...  \n",
       "1995                 9  \n",
       "1996                29  \n",
       "1997                12  \n",
       "1998                42  \n",
       "1999                23  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test[['user_id','user_cnt_0','user_cnt_1','user_cnt_2','user_cnt_3','seller_nunique_0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 7, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.groupby('user_id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合特征\n",
    "\n",
    "### 特征组合进行业务特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点击次数\n",
    "all_data_test = user_col_cnt(all_data_test,  ['seller_path', 'item_path'], '0', 'user_cnt_0')\n",
    "\n",
    "# 不同店铺个数\n",
    "all_data_test = user_col_nunique(all_data_test,  ['seller_path', 'item_path'], '0', 'seller_nunique_0')\n",
    "# ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 36)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看提取的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用countvector，tfidf提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- 知识点四\n",
    "-- 利用countvector，tfidf提取特征\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from scipy import sparse\n",
    "# cntVec = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 1), max_features=100)\n",
    "tfidfVec = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 1), max_features=100)\n",
    "\n",
    "\n",
    "# columns_list = ['seller_path', 'cat_path', 'brand_path', 'action_type_path', 'item_path', 'time_stamp_path']\n",
    "columns_list = ['seller_path']\n",
    "for i, col in enumerate(columns_list):\n",
    "\ttfidfVec.fit(all_data_test[col])\n",
    "\tdata_ = tfidfVec.transform(all_data_test[col])\n",
    "\tif i == 0:\n",
    "\t\tdata_cat = data_\n",
    "\telse:\n",
    "\t\tdata_cat = sparse.hstack((data_cat, data_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重命名 特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(data_cat.toarray())\n",
    "df_tfidf.columns = ['tfidf_' + str(i) for i in df_tfidf.columns]\n",
    "all_data_test = pd.concat([all_data_test, df_tfidf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 136)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embeeding特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Train Word2Vec model\n",
    "\n",
    "model = gensim.models.Word2Vec(all_data_test['seller_path'].apply(lambda x: x.split(' ')), size=100, window=5, min_count=5, workers=4)\n",
    "# model.save(\"product2vec.model\")\n",
    "# model = gensim.models.Word2Vec.load(\"product2vec.model\")\n",
    "\n",
    "def mean_w2v_(x, model, size=100):\n",
    "    try:\n",
    "        i = 0\n",
    "        for word in x.split(' '):\n",
    "            if word in model.wv.vocab:\n",
    "                i += 1\n",
    "                if i == 1:\n",
    "                    vec = np.zeros(size)\n",
    "                vec += model.wv[word]\n",
    "        return vec / i \n",
    "    except:\n",
    "        return  np.zeros(size)\n",
    "\n",
    "\n",
    "def get_mean_w2v(df_data, columns, model, size):\n",
    "    data_array = []\n",
    "    for index, row in df_data.iterrows():\n",
    "        w2v = mean_w2v_(row[columns], model, size)\n",
    "        data_array.append(w2v)\n",
    "    return pd.DataFrame(data_array)\n",
    "\n",
    "df_embeeding = get_mean_w2v(all_data_test, 'seller_path', model, 100)\n",
    "df_embeeding.columns = ['embeeding_' + str(i) for i in df_embeeding.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeeding_0</th>\n",
       "      <th>embeeding_1</th>\n",
       "      <th>embeeding_2</th>\n",
       "      <th>embeeding_3</th>\n",
       "      <th>embeeding_4</th>\n",
       "      <th>embeeding_5</th>\n",
       "      <th>embeeding_6</th>\n",
       "      <th>embeeding_7</th>\n",
       "      <th>embeeding_8</th>\n",
       "      <th>embeeding_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embeeding_90</th>\n",
       "      <th>embeeding_91</th>\n",
       "      <th>embeeding_92</th>\n",
       "      <th>embeeding_93</th>\n",
       "      <th>embeeding_94</th>\n",
       "      <th>embeeding_95</th>\n",
       "      <th>embeeding_96</th>\n",
       "      <th>embeeding_97</th>\n",
       "      <th>embeeding_98</th>\n",
       "      <th>embeeding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.811630</td>\n",
       "      <td>-0.576515</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>-0.303521</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.373185</td>\n",
       "      <td>-0.095445</td>\n",
       "      <td>-1.249770</td>\n",
       "      <td>-0.131301</td>\n",
       "      <td>-0.378220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151749</td>\n",
       "      <td>-0.345193</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.014218</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>-0.533239</td>\n",
       "      <td>0.231678</td>\n",
       "      <td>-0.427409</td>\n",
       "      <td>0.412302</td>\n",
       "      <td>0.850330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.811630</td>\n",
       "      <td>-0.576515</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>-0.303521</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.373185</td>\n",
       "      <td>-0.095445</td>\n",
       "      <td>-1.249770</td>\n",
       "      <td>-0.131301</td>\n",
       "      <td>-0.378220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151749</td>\n",
       "      <td>-0.345193</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.014218</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>-0.533239</td>\n",
       "      <td>0.231678</td>\n",
       "      <td>-0.427409</td>\n",
       "      <td>0.412302</td>\n",
       "      <td>0.850330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.811630</td>\n",
       "      <td>-0.576515</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>-0.303521</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.373185</td>\n",
       "      <td>-0.095445</td>\n",
       "      <td>-1.249770</td>\n",
       "      <td>-0.131301</td>\n",
       "      <td>-0.378220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151749</td>\n",
       "      <td>-0.345193</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.014218</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>-0.533239</td>\n",
       "      <td>0.231678</td>\n",
       "      <td>-0.427409</td>\n",
       "      <td>0.412302</td>\n",
       "      <td>0.850330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.811630</td>\n",
       "      <td>-0.576515</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>-0.303521</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.373185</td>\n",
       "      <td>-0.095445</td>\n",
       "      <td>-1.249770</td>\n",
       "      <td>-0.131301</td>\n",
       "      <td>-0.378220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151749</td>\n",
       "      <td>-0.345193</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.014218</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>-0.533239</td>\n",
       "      <td>0.231678</td>\n",
       "      <td>-0.427409</td>\n",
       "      <td>0.412302</td>\n",
       "      <td>0.850330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.779944</td>\n",
       "      <td>-0.573124</td>\n",
       "      <td>-0.140103</td>\n",
       "      <td>-0.231829</td>\n",
       "      <td>-0.515864</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>0.080954</td>\n",
       "      <td>-0.489231</td>\n",
       "      <td>-0.203817</td>\n",
       "      <td>-0.228702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475462</td>\n",
       "      <td>-0.644581</td>\n",
       "      <td>-0.573855</td>\n",
       "      <td>-0.128846</td>\n",
       "      <td>-0.287453</td>\n",
       "      <td>-0.151249</td>\n",
       "      <td>0.713761</td>\n",
       "      <td>-0.563686</td>\n",
       "      <td>-0.011947</td>\n",
       "      <td>0.135482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embeeding_0  embeeding_1  embeeding_2  embeeding_3  embeeding_4  \\\n",
       "0    -0.811630    -0.576515    -0.256304    -0.303521    -0.006271   \n",
       "1    -0.811630    -0.576515    -0.256304    -0.303521    -0.006271   \n",
       "2    -0.811630    -0.576515    -0.256304    -0.303521    -0.006271   \n",
       "3    -0.811630    -0.576515    -0.256304    -0.303521    -0.006271   \n",
       "4    -0.779944    -0.573124    -0.140103    -0.231829    -0.515864   \n",
       "\n",
       "   embeeding_5  embeeding_6  embeeding_7  embeeding_8  embeeding_9  ...  \\\n",
       "0    -0.373185    -0.095445    -1.249770    -0.131301    -0.378220  ...   \n",
       "1    -0.373185    -0.095445    -1.249770    -0.131301    -0.378220  ...   \n",
       "2    -0.373185    -0.095445    -1.249770    -0.131301    -0.378220  ...   \n",
       "3    -0.373185    -0.095445    -1.249770    -0.131301    -0.378220  ...   \n",
       "4     0.142165     0.080954    -0.489231    -0.203817    -0.228702  ...   \n",
       "\n",
       "   embeeding_90  embeeding_91  embeeding_92  embeeding_93  embeeding_94  \\\n",
       "0      0.151749     -0.345193     -0.033182     -0.014218      0.026865   \n",
       "1      0.151749     -0.345193     -0.033182     -0.014218      0.026865   \n",
       "2      0.151749     -0.345193     -0.033182     -0.014218      0.026865   \n",
       "3      0.151749     -0.345193     -0.033182     -0.014218      0.026865   \n",
       "4      0.475462     -0.644581     -0.573855     -0.128846     -0.287453   \n",
       "\n",
       "   embeeding_95  embeeding_96  embeeding_97  embeeding_98  embeeding_99  \n",
       "0     -0.533239      0.231678     -0.427409      0.412302      0.850330  \n",
       "1     -0.533239      0.231678     -0.427409      0.412302      0.850330  \n",
       "2     -0.533239      0.231678     -0.427409      0.412302      0.850330  \n",
       "3     -0.533239      0.231678     -0.427409      0.412302      0.850330  \n",
       "4     -0.151249      0.713761     -0.563686     -0.011947      0.135482  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeeding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeeding特征和原始特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 136)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_test = pd.concat([all_data_test, df_embeeding],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 236)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- 知识点六\n",
    "-- stacking特征\n",
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss,mean_absolute_error,mean_squared_error\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking 回归特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- 回归\n",
    "-- stacking 回归特征\n",
    "\"\"\"\n",
    "def stacking_reg(clf,train_x,train_y,test_x,clf_name,kf,label_split=None):\n",
    "    train=np.zeros((train_x.shape[0],1))\n",
    "    test=np.zeros((test_x.shape[0],1))\n",
    "    test_pre=np.empty((folds,test_x.shape[0],1))\n",
    "    cv_scores=[]\n",
    "    for i,(train_index,test_index) in enumerate(kf.split(train_x,label_split)):       \n",
    "        tr_x=train_x[train_index]\n",
    "        tr_y=train_y[train_index]\n",
    "        te_x=train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "        if clf_name in [\"rf\",\"ada\",\"gb\",\"et\",\"lr\"]:\n",
    "            clf.fit(tr_x,tr_y)\n",
    "            pre=clf.predict(te_x).reshape(-1,1)\n",
    "            train[test_index]=pre\n",
    "            test_pre[i,:]=clf.predict(test_x).reshape(-1,1)\n",
    "            cv_scores.append(mean_squared_error(te_y, pre))\n",
    "        elif clf_name in [\"xgb\"]:\n",
    "            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-1)\n",
    "            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-1)\n",
    "            z = clf.DMatrix(test_x, label=te_y, missing=-1)\n",
    "            params = {'booster': 'gbtree',\n",
    "                      'eval_metric': 'rmse',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      'nthread': 12\n",
    "                      }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            watchlist = [(train_matrix, 'train'),\n",
    "                         (test_matrix, 'eval')\n",
    "                         ]\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "                train[test_index]=pre\n",
    "                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "                cv_scores.append(mean_squared_error(te_y, pre))\n",
    "\n",
    "        elif clf_name in [\"lgb\"]:\n",
    "            train_matrix = clf.Dataset(tr_x, label=tr_y)\n",
    "            test_matrix = clf.Dataset(te_x, label=te_y)\n",
    "            params = {\n",
    "                      'boosting_type': 'gbdt',\n",
    "                      'objective': 'regression_l2',\n",
    "                      'metric': 'mse',\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'num_leaves': 2**5,\n",
    "                      'lambda_l2': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'learning_rate': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      'nthread': 12,\n",
    "                      'silent': True,\n",
    "                      }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(te_x,num_iteration=model.best_iteration).reshape(-1,1)\n",
    "                train[test_index]=pre\n",
    "                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration).reshape(-1,1)\n",
    "                cv_scores.append(mean_squared_error(te_y, pre))\n",
    "        else:\n",
    "            raise IOError(\"Please add new clf.\")\n",
    "        print(\"%s now score is:\"%clf_name,cv_scores)\n",
    "    test[:]=test_pre.mean(axis=0)\n",
    "    print(\"%s_score_list:\"%clf_name,cv_scores)\n",
    "    print(\"%s_score_mean:\"%clf_name,np.mean(cv_scores))\n",
    "    return train.reshape(-1,1),test.reshape(-1,1)\n",
    "\n",
    "def rf_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    randomforest = RandomForestRegressor(n_estimators=600, max_depth=20, n_jobs=-1, random_state=2017, max_features=\"auto\",verbose=1)\n",
    "    rf_train, rf_test = stacking_reg(randomforest, x_train, y_train, x_valid, \"rf\", kf, label_split=label_split)\n",
    "    return rf_train, rf_test,\"rf_reg\"\n",
    "\n",
    "def ada_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    adaboost = AdaBoostRegressor(n_estimators=30, random_state=2017, learning_rate=0.01)\n",
    "    ada_train, ada_test = stacking_reg(adaboost, x_train, y_train, x_valid, \"ada\", kf, label_split=label_split)\n",
    "    return ada_train, ada_test,\"ada_reg\"\n",
    "\n",
    "def gb_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    gbdt = GradientBoostingRegressor(learning_rate=0.04, n_estimators=100, subsample=0.8, random_state=2017,max_depth=5,verbose=1)\n",
    "    gbdt_train, gbdt_test = stacking_reg(gbdt, x_train, y_train, x_valid, \"gb\", kf, label_split=label_split)\n",
    "    return gbdt_train, gbdt_test,\"gb_reg\"\n",
    "\n",
    "def et_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    extratree = ExtraTreesRegressor(n_estimators=600, max_depth=35, max_features=\"auto\", n_jobs=-1, random_state=2017,verbose=1)\n",
    "    et_train, et_test = stacking_reg(extratree, x_train, y_train, x_valid, \"et\", kf, label_split=label_split)\n",
    "    return et_train, et_test,\"et_reg\"\n",
    "\n",
    "def lr_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    lr_reg=LinearRegression(n_jobs=-1)\n",
    "    lr_train, lr_test = stacking_reg(lr_reg, x_train, y_train, x_valid, \"lr\", kf, label_split=label_split)\n",
    "    return lr_train, lr_test, \"lr_reg\"\n",
    "\n",
    "def xgb_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_reg(xgboost, x_train, y_train, x_valid, \"xgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test,\"xgb_reg\"\n",
    "\n",
    "def lgb_reg(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    lgb_train, lgb_test = stacking_reg(lightgbm, x_train, y_train, x_valid, \"lgb\", kf, label_split=label_split)\n",
    "    return lgb_train, lgb_test,\"lgb_reg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking 分类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- 分类\n",
    "-- stacking 分类特征\n",
    "\"\"\"\n",
    "def stacking_clf(clf,train_x,train_y,test_x,clf_name,kf,label_split=None):\n",
    "    train=np.zeros((train_x.shape[0],1))\n",
    "    test=np.zeros((test_x.shape[0],1))\n",
    "    test_pre=np.empty((folds,test_x.shape[0],1))\n",
    "    cv_scores=[]\n",
    "    for i,(train_index,test_index) in enumerate(kf.split(train_x,label_split)):       \n",
    "        tr_x=train_x[train_index]\n",
    "        tr_y=train_y[train_index]\n",
    "        te_x=train_x[test_index]\n",
    "        te_y = train_y[test_index]\n",
    "\n",
    "        if clf_name in [\"rf\",\"ada\",\"gb\",\"et\",\"lr\",\"knn\",\"gnb\"]:\n",
    "            clf.fit(tr_x,tr_y)\n",
    "            pre=clf.predict_proba(te_x)\n",
    "            \n",
    "            train[test_index]=pre[:,0].reshape(-1,1)\n",
    "            test_pre[i,:]=clf.predict_proba(test_x)[:,0].reshape(-1,1)\n",
    "            \n",
    "            cv_scores.append(log_loss(te_y, pre[:,0].reshape(-1,1)))\n",
    "        elif clf_name in [\"xgb\"]:\n",
    "            train_matrix = clf.DMatrix(tr_x, label=tr_y, missing=-1)\n",
    "            test_matrix = clf.DMatrix(te_x, label=te_y, missing=-1)\n",
    "            z = clf.DMatrix(test_x, missing=-1)\n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'multi:softprob',\n",
    "                      'eval_metric': 'mlogloss',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      \"num_class\": 2\n",
    "                      }\n",
    "\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            watchlist = [(train_matrix, 'train'),\n",
    "                         (test_matrix, 'eval')\n",
    "                         ]\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix, num_boost_round=num_round,evals=watchlist,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(test_matrix,ntree_limit=model.best_ntree_limit)\n",
    "                train[test_index]=pre[:,0].reshape(-1,1)\n",
    "                test_pre[i, :]= model.predict(z, ntree_limit=model.best_ntree_limit)[:,0].reshape(-1,1)\n",
    "                cv_scores.append(log_loss(te_y, pre[:,0].reshape(-1,1)))\n",
    "        elif clf_name in [\"lgb\"]:\n",
    "            train_matrix = clf.Dataset(tr_x, label=tr_y)\n",
    "            test_matrix = clf.Dataset(te_x, label=te_y)\n",
    "            params = {\n",
    "                      'boosting_type': 'gbdt',\n",
    "                      #'boosting_type': 'dart',\n",
    "                      'objective': 'multiclass',\n",
    "                      'metric': 'multi_logloss',\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'num_leaves': 2**5,\n",
    "                      'lambda_l2': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'learning_rate': 0.03,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2017,\n",
    "                      \"num_class\": 2,\n",
    "                      'silent': True,\n",
    "                      }\n",
    "            num_round = 10000\n",
    "            early_stopping_rounds = 100\n",
    "            if test_matrix:\n",
    "                model = clf.train(params, train_matrix,num_round,valid_sets=test_matrix,\n",
    "                                  early_stopping_rounds=early_stopping_rounds\n",
    "                                  )\n",
    "                pre= model.predict(te_x,num_iteration=model.best_iteration)\n",
    "                print('AAAAAA',test_x.shape)\n",
    "                train[test_index]=pre[:,0].reshape(-1,1)\n",
    "                test_pre[i, :]= model.predict(test_x, num_iteration=model.best_iteration)[:,0].reshape(-1,1)\n",
    "                cv_scores.append(log_loss(te_y, pre[:,0].reshape(-1,1)))\n",
    "        else:\n",
    "            raise IOError(\"Please add new clf.\")\n",
    "        print(\"%s now score is:\"%clf_name,cv_scores)\n",
    "    test[:]=test_pre.mean(axis=0)\n",
    "    print(\"%s_score_list:\"%clf_name,cv_scores)\n",
    "    print(\"%s_score_mean:\"%clf_name,np.mean(cv_scores))\n",
    "    return train.reshape(-1,1),test.reshape(-1,1)\n",
    "\n",
    "def rf_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    randomforest = RandomForestClassifier(n_estimators=1200, max_depth=20, n_jobs=-1, random_state=2017, max_features=\"auto\",verbose=1)\n",
    "    rf_train, rf_test = stacking_clf(randomforest, x_train, y_train, x_valid, \"rf\", kf, label_split=label_split)\n",
    "    return rf_train, rf_test,\"rf\"\n",
    "\n",
    "def ada_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    adaboost = AdaBoostClassifier(n_estimators=50, random_state=2017, learning_rate=0.01)\n",
    "    ada_train, ada_test = stacking_clf(adaboost, x_train, y_train, x_valid, \"ada\", kf, label_split=label_split)\n",
    "    return ada_train, ada_test,\"ada\"\n",
    "\n",
    "def gb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    gbdt = GradientBoostingClassifier(learning_rate=0.04, n_estimators=100, subsample=0.8, random_state=2017,max_depth=5,verbose=1)\n",
    "    gbdt_train, gbdt_test = stacking_clf(gbdt, x_train, y_train, x_valid, \"gb\", kf, label_split=label_split)\n",
    "    return gbdt_train, gbdt_test,\"gb\"\n",
    "\n",
    "def et_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    extratree = ExtraTreesClassifier(n_estimators=1200, max_depth=35, max_features=\"auto\", n_jobs=-1, random_state=2017,verbose=1)\n",
    "    et_train, et_test = stacking_clf(extratree, x_train, y_train, x_valid, \"et\", kf, label_split=label_split)\n",
    "    return et_train, et_test,\"et\"\n",
    "\n",
    "def xgb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_clf(xgboost, x_train, y_train, x_valid, \"xgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test,\"xgb\"\n",
    "\n",
    "def lgb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    xgb_train, xgb_test = stacking_clf(lightgbm, x_train, y_train, x_valid, \"lgb\", kf, label_split=label_split)\n",
    "    return xgb_train, xgb_test,\"lgb\"\n",
    "\n",
    "def gnb_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    gnb=GaussianNB()\n",
    "    gnb_train, gnb_test = stacking_clf(gnb, x_train, y_train, x_valid, \"gnb\", kf, label_split=label_split)\n",
    "    return gnb_train, gnb_test,\"gnb\"\n",
    "\n",
    "def lr_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    logisticregression=LogisticRegression(n_jobs=-1,random_state=2017,C=0.1,max_iter=200)\n",
    "    lr_train, lr_test = stacking_clf(logisticregression, x_train, y_train, x_valid, \"lr\", kf, label_split=label_split)\n",
    "    return lr_train, lr_test, \"lr\"\n",
    "\n",
    "def knn_clf(x_train, y_train, x_valid, kf, label_split=None):\n",
    "    kneighbors=KNeighborsClassifier(n_neighbors=200,n_jobs=-1)\n",
    "    knn_train, knn_test = stacking_clf(kneighbors, x_train, y_train, x_valid, \"lr\", kf, label_split=label_split)\n",
    "    return knn_train, knn_test, \"knn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取训练和验证数据(为stacking特征做准备)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 236)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 228), 228, (2000, 236))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test[features_columns].shape,len(features_columns),all_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [c for c in all_data_test.columns if c not in ['label', 'prob', 'seller_path', 'cat_path', 'brand_path', 'action_type_path', 'item_path', 'time_stamp_path']]\n",
    "x_train = all_data_test[~all_data_test['label'].isna()][features_columns].values\n",
    "y_train = all_data_test[~all_data_test['label'].isna()]['label'].values\n",
    "x_valid = all_data_test[all_data_test['label'].isna()][features_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理函数值inf以及nan情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data):\n",
    "    where_are_nan = np.isnan(data)\n",
    "    where_are_inf = np.isinf(data)\n",
    "    data[where_are_nan] = 0\n",
    "    data[where_are_inf] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.float_(get_matrix(np.float_(x_train)))\n",
    "y_train = np.int_(y_train)\n",
    "x_valid = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 228)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入划分数据函数 设stacking特征为5折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import lightgbm,xgboost\n",
    "\n",
    "\n",
    "folds = 5\n",
    "seed = 1\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用lgb和xgb分类模型构造stacking特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_list = [lgb_clf, xgb_clf, lgb_reg, xgb_reg]\n",
    "# clf_list_col = ['lgb_clf', 'xgb_clf', 'lgb_reg', 'xgb_reg']\n",
    "\n",
    "clf_list = [lgb_clf, xgb_clf]\n",
    "clf_list_col = ['lgb_clf', 'xgb_clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型，获取stacking特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 228), (2000,), (2000, 228))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.240319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.240122\n",
      "[3]\tvalid_0's multi_logloss: 0.239833\n",
      "[4]\tvalid_0's multi_logloss: 0.239505\n",
      "[5]\tvalid_0's multi_logloss: 0.239508\n",
      "[6]\tvalid_0's multi_logloss: 0.239234\n",
      "[7]\tvalid_0's multi_logloss: 0.23894\n",
      "[8]\tvalid_0's multi_logloss: 0.238671\n",
      "[9]\tvalid_0's multi_logloss: 0.238576\n",
      "[10]\tvalid_0's multi_logloss: 0.238459\n",
      "[11]\tvalid_0's multi_logloss: 0.238496\n",
      "[12]\tvalid_0's multi_logloss: 0.238343\n",
      "[13]\tvalid_0's multi_logloss: 0.238338\n",
      "[14]\tvalid_0's multi_logloss: 0.23838\n",
      "[15]\tvalid_0's multi_logloss: 0.238456\n",
      "[16]\tvalid_0's multi_logloss: 0.23872\n",
      "[17]\tvalid_0's multi_logloss: 0.238728\n",
      "[18]\tvalid_0's multi_logloss: 0.238966\n",
      "[19]\tvalid_0's multi_logloss: 0.239273\n",
      "[20]\tvalid_0's multi_logloss: 0.239236\n",
      "[21]\tvalid_0's multi_logloss: 0.239341\n",
      "[22]\tvalid_0's multi_logloss: 0.239368\n",
      "[23]\tvalid_0's multi_logloss: 0.239362\n",
      "[24]\tvalid_0's multi_logloss: 0.239557\n",
      "[25]\tvalid_0's multi_logloss: 0.239464\n",
      "[26]\tvalid_0's multi_logloss: 0.239331\n",
      "[27]\tvalid_0's multi_logloss: 0.239143\n",
      "[28]\tvalid_0's multi_logloss: 0.239023\n",
      "[29]\tvalid_0's multi_logloss: 0.238876\n",
      "[30]\tvalid_0's multi_logloss: 0.238852\n",
      "[31]\tvalid_0's multi_logloss: 0.238753\n",
      "[32]\tvalid_0's multi_logloss: 0.238747\n",
      "[33]\tvalid_0's multi_logloss: 0.238843\n",
      "[34]\tvalid_0's multi_logloss: 0.238901\n",
      "[35]\tvalid_0's multi_logloss: 0.239096\n",
      "[36]\tvalid_0's multi_logloss: 0.23917\n",
      "[37]\tvalid_0's multi_logloss: 0.239336\n",
      "[38]\tvalid_0's multi_logloss: 0.239502\n",
      "[39]\tvalid_0's multi_logloss: 0.239401\n",
      "[40]\tvalid_0's multi_logloss: 0.239431\n",
      "[41]\tvalid_0's multi_logloss: 0.23947\n",
      "[42]\tvalid_0's multi_logloss: 0.239373\n",
      "[43]\tvalid_0's multi_logloss: 0.239082\n",
      "[44]\tvalid_0's multi_logloss: 0.239263\n",
      "[45]\tvalid_0's multi_logloss: 0.239453\n",
      "[46]\tvalid_0's multi_logloss: 0.239464\n",
      "[47]\tvalid_0's multi_logloss: 0.239661\n",
      "[48]\tvalid_0's multi_logloss: 0.239891\n",
      "[49]\tvalid_0's multi_logloss: 0.239938\n",
      "[50]\tvalid_0's multi_logloss: 0.240218\n",
      "[51]\tvalid_0's multi_logloss: 0.240571\n",
      "[52]\tvalid_0's multi_logloss: 0.240582\n",
      "[53]\tvalid_0's multi_logloss: 0.240633\n",
      "[54]\tvalid_0's multi_logloss: 0.240791\n",
      "[55]\tvalid_0's multi_logloss: 0.241202\n",
      "[56]\tvalid_0's multi_logloss: 0.241641\n",
      "[57]\tvalid_0's multi_logloss: 0.241706\n",
      "[58]\tvalid_0's multi_logloss: 0.241838\n",
      "[59]\tvalid_0's multi_logloss: 0.242034\n",
      "[60]\tvalid_0's multi_logloss: 0.24209\n",
      "[61]\tvalid_0's multi_logloss: 0.242233\n",
      "[62]\tvalid_0's multi_logloss: 0.242221\n",
      "[63]\tvalid_0's multi_logloss: 0.242278\n",
      "[64]\tvalid_0's multi_logloss: 0.242298\n",
      "[65]\tvalid_0's multi_logloss: 0.242393\n",
      "[66]\tvalid_0's multi_logloss: 0.242372\n",
      "[67]\tvalid_0's multi_logloss: 0.242441\n",
      "[68]\tvalid_0's multi_logloss: 0.242607\n",
      "[69]\tvalid_0's multi_logloss: 0.24268\n",
      "[70]\tvalid_0's multi_logloss: 0.242761\n",
      "[71]\tvalid_0's multi_logloss: 0.243049\n",
      "[72]\tvalid_0's multi_logloss: 0.243025\n",
      "[73]\tvalid_0's multi_logloss: 0.243046\n",
      "[74]\tvalid_0's multi_logloss: 0.243325\n",
      "[75]\tvalid_0's multi_logloss: 0.243355\n",
      "[76]\tvalid_0's multi_logloss: 0.243399\n",
      "[77]\tvalid_0's multi_logloss: 0.243608\n",
      "[78]\tvalid_0's multi_logloss: 0.243763\n",
      "[79]\tvalid_0's multi_logloss: 0.244128\n",
      "[80]\tvalid_0's multi_logloss: 0.244327\n",
      "[81]\tvalid_0's multi_logloss: 0.244385\n",
      "[82]\tvalid_0's multi_logloss: 0.2445\n",
      "[83]\tvalid_0's multi_logloss: 0.244654\n",
      "[84]\tvalid_0's multi_logloss: 0.244778\n",
      "[85]\tvalid_0's multi_logloss: 0.245032\n",
      "[86]\tvalid_0's multi_logloss: 0.245321\n",
      "[87]\tvalid_0's multi_logloss: 0.245514\n",
      "[88]\tvalid_0's multi_logloss: 0.245804\n",
      "[89]\tvalid_0's multi_logloss: 0.246117\n",
      "[90]\tvalid_0's multi_logloss: 0.246329\n",
      "[91]\tvalid_0's multi_logloss: 0.246573\n",
      "[92]\tvalid_0's multi_logloss: 0.246821\n",
      "[93]\tvalid_0's multi_logloss: 0.247073\n",
      "[94]\tvalid_0's multi_logloss: 0.247243\n",
      "[95]\tvalid_0's multi_logloss: 0.247593\n",
      "[96]\tvalid_0's multi_logloss: 0.247841\n",
      "[97]\tvalid_0's multi_logloss: 0.247956\n",
      "[98]\tvalid_0's multi_logloss: 0.24818\n",
      "[99]\tvalid_0's multi_logloss: 0.248481\n",
      "[100]\tvalid_0's multi_logloss: 0.248579\n",
      "[101]\tvalid_0's multi_logloss: 0.248915\n",
      "[102]\tvalid_0's multi_logloss: 0.249285\n",
      "[103]\tvalid_0's multi_logloss: 0.249511\n",
      "[104]\tvalid_0's multi_logloss: 0.249757\n",
      "[105]\tvalid_0's multi_logloss: 0.249919\n",
      "[106]\tvalid_0's multi_logloss: 0.250057\n",
      "[107]\tvalid_0's multi_logloss: 0.250265\n",
      "[108]\tvalid_0's multi_logloss: 0.250578\n",
      "[109]\tvalid_0's multi_logloss: 0.250744\n",
      "[110]\tvalid_0's multi_logloss: 0.25084\n",
      "[111]\tvalid_0's multi_logloss: 0.251161\n",
      "[112]\tvalid_0's multi_logloss: 0.251435\n",
      "[113]\tvalid_0's multi_logloss: 0.251553\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 0.238338\n",
      "AAAAAA (2000, 228)\n",
      "lgb now score is: [2.6300821660643603]\n",
      "[1]\tvalid_0's multi_logloss: 0.281961\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.282346\n",
      "[3]\tvalid_0's multi_logloss: 0.282542\n",
      "[4]\tvalid_0's multi_logloss: 0.282989\n",
      "[5]\tvalid_0's multi_logloss: 0.283497\n",
      "[6]\tvalid_0's multi_logloss: 0.283891\n",
      "[7]\tvalid_0's multi_logloss: 0.284392\n",
      "[8]\tvalid_0's multi_logloss: 0.284761\n",
      "[9]\tvalid_0's multi_logloss: 0.285154\n",
      "[10]\tvalid_0's multi_logloss: 0.285396\n",
      "[11]\tvalid_0's multi_logloss: 0.285522\n",
      "[12]\tvalid_0's multi_logloss: 0.285866\n",
      "[13]\tvalid_0's multi_logloss: 0.28654\n",
      "[14]\tvalid_0's multi_logloss: 0.286875\n",
      "[15]\tvalid_0's multi_logloss: 0.287276\n",
      "[16]\tvalid_0's multi_logloss: 0.287694\n",
      "[17]\tvalid_0's multi_logloss: 0.288183\n",
      "[18]\tvalid_0's multi_logloss: 0.288258\n",
      "[19]\tvalid_0's multi_logloss: 0.288217\n",
      "[20]\tvalid_0's multi_logloss: 0.288279\n",
      "[21]\tvalid_0's multi_logloss: 0.288781\n",
      "[22]\tvalid_0's multi_logloss: 0.289246\n",
      "[23]\tvalid_0's multi_logloss: 0.2896\n",
      "[24]\tvalid_0's multi_logloss: 0.289392\n",
      "[25]\tvalid_0's multi_logloss: 0.289817\n",
      "[26]\tvalid_0's multi_logloss: 0.290084\n",
      "[27]\tvalid_0's multi_logloss: 0.290399\n",
      "[28]\tvalid_0's multi_logloss: 0.290568\n",
      "[29]\tvalid_0's multi_logloss: 0.29091\n",
      "[30]\tvalid_0's multi_logloss: 0.291253\n",
      "[31]\tvalid_0's multi_logloss: 0.291485\n",
      "[32]\tvalid_0's multi_logloss: 0.292036\n",
      "[33]\tvalid_0's multi_logloss: 0.292378\n",
      "[34]\tvalid_0's multi_logloss: 0.292646\n",
      "[35]\tvalid_0's multi_logloss: 0.293235\n",
      "[36]\tvalid_0's multi_logloss: 0.293367\n",
      "[37]\tvalid_0's multi_logloss: 0.294026\n",
      "[38]\tvalid_0's multi_logloss: 0.294373\n",
      "[39]\tvalid_0's multi_logloss: 0.294553\n",
      "[40]\tvalid_0's multi_logloss: 0.294951\n",
      "[41]\tvalid_0's multi_logloss: 0.295322\n",
      "[42]\tvalid_0's multi_logloss: 0.295609\n",
      "[43]\tvalid_0's multi_logloss: 0.296242\n",
      "[44]\tvalid_0's multi_logloss: 0.296788\n",
      "[45]\tvalid_0's multi_logloss: 0.297203\n",
      "[46]\tvalid_0's multi_logloss: 0.297526\n",
      "[47]\tvalid_0's multi_logloss: 0.297891\n",
      "[48]\tvalid_0's multi_logloss: 0.298571\n",
      "[49]\tvalid_0's multi_logloss: 0.298882\n",
      "[50]\tvalid_0's multi_logloss: 0.29923\n",
      "[51]\tvalid_0's multi_logloss: 0.299619\n",
      "[52]\tvalid_0's multi_logloss: 0.29997\n",
      "[53]\tvalid_0's multi_logloss: 0.30027\n",
      "[54]\tvalid_0's multi_logloss: 0.300505\n",
      "[55]\tvalid_0's multi_logloss: 0.301027\n",
      "[56]\tvalid_0's multi_logloss: 0.301547\n",
      "[57]\tvalid_0's multi_logloss: 0.301837\n",
      "[58]\tvalid_0's multi_logloss: 0.302103\n",
      "[59]\tvalid_0's multi_logloss: 0.302483\n",
      "[60]\tvalid_0's multi_logloss: 0.302821\n",
      "[61]\tvalid_0's multi_logloss: 0.303577\n",
      "[62]\tvalid_0's multi_logloss: 0.303865\n",
      "[63]\tvalid_0's multi_logloss: 0.304258\n",
      "[64]\tvalid_0's multi_logloss: 0.304609\n",
      "[65]\tvalid_0's multi_logloss: 0.304998\n",
      "[66]\tvalid_0's multi_logloss: 0.305624\n",
      "[67]\tvalid_0's multi_logloss: 0.306175\n",
      "[68]\tvalid_0's multi_logloss: 0.306525\n",
      "[69]\tvalid_0's multi_logloss: 0.306891\n",
      "[70]\tvalid_0's multi_logloss: 0.307223\n",
      "[71]\tvalid_0's multi_logloss: 0.307446\n",
      "[72]\tvalid_0's multi_logloss: 0.307727\n",
      "[73]\tvalid_0's multi_logloss: 0.308081\n",
      "[74]\tvalid_0's multi_logloss: 0.308482\n",
      "[75]\tvalid_0's multi_logloss: 0.308865\n",
      "[76]\tvalid_0's multi_logloss: 0.309104\n",
      "[77]\tvalid_0's multi_logloss: 0.309356\n",
      "[78]\tvalid_0's multi_logloss: 0.309796\n",
      "[79]\tvalid_0's multi_logloss: 0.310323\n",
      "[80]\tvalid_0's multi_logloss: 0.310566\n",
      "[81]\tvalid_0's multi_logloss: 0.310868\n",
      "[82]\tvalid_0's multi_logloss: 0.311258\n",
      "[83]\tvalid_0's multi_logloss: 0.31164\n",
      "[84]\tvalid_0's multi_logloss: 0.312102\n",
      "[85]\tvalid_0's multi_logloss: 0.312479\n",
      "[86]\tvalid_0's multi_logloss: 0.31298\n",
      "[87]\tvalid_0's multi_logloss: 0.313412\n",
      "[88]\tvalid_0's multi_logloss: 0.313932\n",
      "[89]\tvalid_0's multi_logloss: 0.314562\n",
      "[90]\tvalid_0's multi_logloss: 0.314956\n",
      "[91]\tvalid_0's multi_logloss: 0.315315\n",
      "[92]\tvalid_0's multi_logloss: 0.315713\n",
      "[93]\tvalid_0's multi_logloss: 0.316147\n",
      "[94]\tvalid_0's multi_logloss: 0.31646\n",
      "[95]\tvalid_0's multi_logloss: 0.317024\n",
      "[96]\tvalid_0's multi_logloss: 0.317425\n",
      "[97]\tvalid_0's multi_logloss: 0.317628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\tvalid_0's multi_logloss: 0.317971\n",
      "[99]\tvalid_0's multi_logloss: 0.318236\n",
      "[100]\tvalid_0's multi_logloss: 0.3186\n",
      "[101]\tvalid_0's multi_logloss: 0.318946\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 0.281961\n",
      "AAAAAA (2000, 228)\n",
      "lgb now score is: [2.6300821660643603, 2.589485985152662]\n",
      "[1]\tvalid_0's multi_logloss: 0.253852\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.253789\n",
      "[3]\tvalid_0's multi_logloss: 0.253905\n",
      "[4]\tvalid_0's multi_logloss: 0.254008\n",
      "[5]\tvalid_0's multi_logloss: 0.253926\n",
      "[6]\tvalid_0's multi_logloss: 0.254072\n",
      "[7]\tvalid_0's multi_logloss: 0.254134\n",
      "[8]\tvalid_0's multi_logloss: 0.254065\n",
      "[9]\tvalid_0's multi_logloss: 0.253962\n",
      "[10]\tvalid_0's multi_logloss: 0.253941\n",
      "[11]\tvalid_0's multi_logloss: 0.254117\n",
      "[12]\tvalid_0's multi_logloss: 0.254331\n",
      "[13]\tvalid_0's multi_logloss: 0.254395\n",
      "[14]\tvalid_0's multi_logloss: 0.254408\n",
      "[15]\tvalid_0's multi_logloss: 0.254388\n",
      "[16]\tvalid_0's multi_logloss: 0.25451\n",
      "[17]\tvalid_0's multi_logloss: 0.254572\n",
      "[18]\tvalid_0's multi_logloss: 0.254833\n",
      "[19]\tvalid_0's multi_logloss: 0.254912\n",
      "[20]\tvalid_0's multi_logloss: 0.255021\n",
      "[21]\tvalid_0's multi_logloss: 0.25527\n",
      "[22]\tvalid_0's multi_logloss: 0.255422\n",
      "[23]\tvalid_0's multi_logloss: 0.255507\n",
      "[24]\tvalid_0's multi_logloss: 0.255827\n",
      "[25]\tvalid_0's multi_logloss: 0.255833\n",
      "[26]\tvalid_0's multi_logloss: 0.256122\n",
      "[27]\tvalid_0's multi_logloss: 0.256497\n",
      "[28]\tvalid_0's multi_logloss: 0.256886\n",
      "[29]\tvalid_0's multi_logloss: 0.257038\n",
      "[30]\tvalid_0's multi_logloss: 0.257398\n",
      "[31]\tvalid_0's multi_logloss: 0.257576\n",
      "[32]\tvalid_0's multi_logloss: 0.257777\n",
      "[33]\tvalid_0's multi_logloss: 0.258088\n",
      "[34]\tvalid_0's multi_logloss: 0.258031\n",
      "[35]\tvalid_0's multi_logloss: 0.258298\n",
      "[36]\tvalid_0's multi_logloss: 0.258872\n",
      "[37]\tvalid_0's multi_logloss: 0.258883\n",
      "[38]\tvalid_0's multi_logloss: 0.259018\n",
      "[39]\tvalid_0's multi_logloss: 0.259435\n",
      "[40]\tvalid_0's multi_logloss: 0.259905\n",
      "[41]\tvalid_0's multi_logloss: 0.260422\n",
      "[42]\tvalid_0's multi_logloss: 0.260436\n",
      "[43]\tvalid_0's multi_logloss: 0.260668\n",
      "[44]\tvalid_0's multi_logloss: 0.260918\n",
      "[45]\tvalid_0's multi_logloss: 0.261129\n",
      "[46]\tvalid_0's multi_logloss: 0.261513\n",
      "[47]\tvalid_0's multi_logloss: 0.261934\n",
      "[48]\tvalid_0's multi_logloss: 0.262345\n",
      "[49]\tvalid_0's multi_logloss: 0.262686\n",
      "[50]\tvalid_0's multi_logloss: 0.263147\n",
      "[51]\tvalid_0's multi_logloss: 0.263525\n",
      "[52]\tvalid_0's multi_logloss: 0.264033\n",
      "[53]\tvalid_0's multi_logloss: 0.264319\n",
      "[54]\tvalid_0's multi_logloss: 0.2647\n",
      "[55]\tvalid_0's multi_logloss: 0.26495\n",
      "[56]\tvalid_0's multi_logloss: 0.265324\n",
      "[57]\tvalid_0's multi_logloss: 0.265181\n",
      "[58]\tvalid_0's multi_logloss: 0.26512\n",
      "[59]\tvalid_0's multi_logloss: 0.265318\n",
      "[60]\tvalid_0's multi_logloss: 0.265689\n",
      "[61]\tvalid_0's multi_logloss: 0.265689\n",
      "[62]\tvalid_0's multi_logloss: 0.265588\n",
      "[63]\tvalid_0's multi_logloss: 0.266008\n",
      "[64]\tvalid_0's multi_logloss: 0.266177\n",
      "[65]\tvalid_0's multi_logloss: 0.266324\n",
      "[66]\tvalid_0's multi_logloss: 0.266485\n",
      "[67]\tvalid_0's multi_logloss: 0.266576\n",
      "[68]\tvalid_0's multi_logloss: 0.266683\n",
      "[69]\tvalid_0's multi_logloss: 0.267046\n",
      "[70]\tvalid_0's multi_logloss: 0.267207\n",
      "[71]\tvalid_0's multi_logloss: 0.267445\n",
      "[72]\tvalid_0's multi_logloss: 0.267349\n",
      "[73]\tvalid_0's multi_logloss: 0.267444\n",
      "[74]\tvalid_0's multi_logloss: 0.267415\n",
      "[75]\tvalid_0's multi_logloss: 0.267617\n",
      "[76]\tvalid_0's multi_logloss: 0.267815\n",
      "[77]\tvalid_0's multi_logloss: 0.267929\n",
      "[78]\tvalid_0's multi_logloss: 0.268068\n",
      "[79]\tvalid_0's multi_logloss: 0.268169\n",
      "[80]\tvalid_0's multi_logloss: 0.268331\n",
      "[81]\tvalid_0's multi_logloss: 0.268497\n",
      "[82]\tvalid_0's multi_logloss: 0.268818\n",
      "[83]\tvalid_0's multi_logloss: 0.268991\n",
      "[84]\tvalid_0's multi_logloss: 0.26945\n",
      "[85]\tvalid_0's multi_logloss: 0.269595\n",
      "[86]\tvalid_0's multi_logloss: 0.269548\n",
      "[87]\tvalid_0's multi_logloss: 0.269768\n",
      "[88]\tvalid_0's multi_logloss: 0.269746\n",
      "[89]\tvalid_0's multi_logloss: 0.269972\n",
      "[90]\tvalid_0's multi_logloss: 0.270202\n",
      "[91]\tvalid_0's multi_logloss: 0.270521\n",
      "[92]\tvalid_0's multi_logloss: 0.270794\n",
      "[93]\tvalid_0's multi_logloss: 0.271071\n",
      "[94]\tvalid_0's multi_logloss: 0.271123\n",
      "[95]\tvalid_0's multi_logloss: 0.271416\n",
      "[96]\tvalid_0's multi_logloss: 0.271508\n",
      "[97]\tvalid_0's multi_logloss: 0.271969\n",
      "[98]\tvalid_0's multi_logloss: 0.272064\n",
      "[99]\tvalid_0's multi_logloss: 0.272076\n",
      "[100]\tvalid_0's multi_logloss: 0.272408\n",
      "[101]\tvalid_0's multi_logloss: 0.272433\n",
      "[102]\tvalid_0's multi_logloss: 0.272729\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 0.253789\n",
      "AAAAAA (2000, 228)\n",
      "lgb now score is: [2.6300821660643603, 2.589485985152662, 2.5884166050143556]\n",
      "[1]\tvalid_0's multi_logloss: 0.208024\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.208219\n",
      "[3]\tvalid_0's multi_logloss: 0.208431\n",
      "[4]\tvalid_0's multi_logloss: 0.208535\n",
      "[5]\tvalid_0's multi_logloss: 0.208332\n",
      "[6]\tvalid_0's multi_logloss: 0.208558\n",
      "[7]\tvalid_0's multi_logloss: 0.208713\n",
      "[8]\tvalid_0's multi_logloss: 0.208684\n",
      "[9]\tvalid_0's multi_logloss: 0.208718\n",
      "[10]\tvalid_0's multi_logloss: 0.208644\n",
      "[11]\tvalid_0's multi_logloss: 0.208865\n",
      "[12]\tvalid_0's multi_logloss: 0.208731\n",
      "[13]\tvalid_0's multi_logloss: 0.208828\n",
      "[14]\tvalid_0's multi_logloss: 0.208616\n",
      "[15]\tvalid_0's multi_logloss: 0.208678\n",
      "[16]\tvalid_0's multi_logloss: 0.20843\n",
      "[17]\tvalid_0's multi_logloss: 0.208521\n",
      "[18]\tvalid_0's multi_logloss: 0.20813\n",
      "[19]\tvalid_0's multi_logloss: 0.208091\n",
      "[20]\tvalid_0's multi_logloss: 0.208265\n",
      "[21]\tvalid_0's multi_logloss: 0.208207\n",
      "[22]\tvalid_0's multi_logloss: 0.208344\n",
      "[23]\tvalid_0's multi_logloss: 0.20826\n",
      "[24]\tvalid_0's multi_logloss: 0.208422\n",
      "[25]\tvalid_0's multi_logloss: 0.208601\n",
      "[26]\tvalid_0's multi_logloss: 0.20841\n",
      "[27]\tvalid_0's multi_logloss: 0.208415\n",
      "[28]\tvalid_0's multi_logloss: 0.208519\n",
      "[29]\tvalid_0's multi_logloss: 0.208456\n",
      "[30]\tvalid_0's multi_logloss: 0.208684\n",
      "[31]\tvalid_0's multi_logloss: 0.208774\n",
      "[32]\tvalid_0's multi_logloss: 0.208784\n",
      "[33]\tvalid_0's multi_logloss: 0.208849\n",
      "[34]\tvalid_0's multi_logloss: 0.208721\n",
      "[35]\tvalid_0's multi_logloss: 0.208629\n",
      "[36]\tvalid_0's multi_logloss: 0.20853\n",
      "[37]\tvalid_0's multi_logloss: 0.20864\n",
      "[38]\tvalid_0's multi_logloss: 0.208729\n",
      "[39]\tvalid_0's multi_logloss: 0.208952\n",
      "[40]\tvalid_0's multi_logloss: 0.209093\n",
      "[41]\tvalid_0's multi_logloss: 0.209403\n",
      "[42]\tvalid_0's multi_logloss: 0.209539\n",
      "[43]\tvalid_0's multi_logloss: 0.209504\n",
      "[44]\tvalid_0's multi_logloss: 0.209957\n",
      "[45]\tvalid_0's multi_logloss: 0.209936\n",
      "[46]\tvalid_0's multi_logloss: 0.209775\n",
      "[47]\tvalid_0's multi_logloss: 0.209774\n",
      "[48]\tvalid_0's multi_logloss: 0.209811\n",
      "[49]\tvalid_0's multi_logloss: 0.210093\n",
      "[50]\tvalid_0's multi_logloss: 0.210251\n",
      "[51]\tvalid_0's multi_logloss: 0.210431\n",
      "[52]\tvalid_0's multi_logloss: 0.210529\n",
      "[53]\tvalid_0's multi_logloss: 0.210888\n",
      "[54]\tvalid_0's multi_logloss: 0.211116\n",
      "[55]\tvalid_0's multi_logloss: 0.211104\n",
      "[56]\tvalid_0's multi_logloss: 0.211344\n",
      "[57]\tvalid_0's multi_logloss: 0.211378\n",
      "[58]\tvalid_0's multi_logloss: 0.211436\n",
      "[59]\tvalid_0's multi_logloss: 0.211436\n",
      "[60]\tvalid_0's multi_logloss: 0.211528\n",
      "[61]\tvalid_0's multi_logloss: 0.211618\n",
      "[62]\tvalid_0's multi_logloss: 0.21182\n",
      "[63]\tvalid_0's multi_logloss: 0.212036\n",
      "[64]\tvalid_0's multi_logloss: 0.212315\n",
      "[65]\tvalid_0's multi_logloss: 0.212373\n",
      "[66]\tvalid_0's multi_logloss: 0.212501\n",
      "[67]\tvalid_0's multi_logloss: 0.212394\n",
      "[68]\tvalid_0's multi_logloss: 0.212659\n",
      "[69]\tvalid_0's multi_logloss: 0.212922\n",
      "[70]\tvalid_0's multi_logloss: 0.213204\n",
      "[71]\tvalid_0's multi_logloss: 0.213179\n",
      "[72]\tvalid_0's multi_logloss: 0.213234\n",
      "[73]\tvalid_0's multi_logloss: 0.213422\n",
      "[74]\tvalid_0's multi_logloss: 0.213404\n",
      "[75]\tvalid_0's multi_logloss: 0.21356\n",
      "[76]\tvalid_0's multi_logloss: 0.213767\n",
      "[77]\tvalid_0's multi_logloss: 0.213669\n",
      "[78]\tvalid_0's multi_logloss: 0.213754\n",
      "[79]\tvalid_0's multi_logloss: 0.213957\n",
      "[80]\tvalid_0's multi_logloss: 0.214028\n",
      "[81]\tvalid_0's multi_logloss: 0.214062\n",
      "[82]\tvalid_0's multi_logloss: 0.214139\n",
      "[83]\tvalid_0's multi_logloss: 0.21416\n",
      "[84]\tvalid_0's multi_logloss: 0.214175\n",
      "[85]\tvalid_0's multi_logloss: 0.214375\n",
      "[86]\tvalid_0's multi_logloss: 0.214552\n",
      "[87]\tvalid_0's multi_logloss: 0.214528\n",
      "[88]\tvalid_0's multi_logloss: 0.214705\n",
      "[89]\tvalid_0's multi_logloss: 0.214911\n",
      "[90]\tvalid_0's multi_logloss: 0.21507\n",
      "[91]\tvalid_0's multi_logloss: 0.215441\n",
      "[92]\tvalid_0's multi_logloss: 0.215381\n",
      "[93]\tvalid_0's multi_logloss: 0.215678\n",
      "[94]\tvalid_0's multi_logloss: 0.215709\n",
      "[95]\tvalid_0's multi_logloss: 0.215943\n",
      "[96]\tvalid_0's multi_logloss: 0.216137\n",
      "[97]\tvalid_0's multi_logloss: 0.216144\n",
      "[98]\tvalid_0's multi_logloss: 0.2164\n",
      "[99]\tvalid_0's multi_logloss: 0.216823\n",
      "[100]\tvalid_0's multi_logloss: 0.216945\n",
      "[101]\tvalid_0's multi_logloss: 0.217106\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 0.208024\n",
      "AAAAAA (2000, 228)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb now score is: [2.6300821660643603, 2.589485985152662, 2.5884166050143556, 2.5602029903385746]\n",
      "[1]\tvalid_0's multi_logloss: 0.213981\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.21363\n",
      "[3]\tvalid_0's multi_logloss: 0.213469\n",
      "[4]\tvalid_0's multi_logloss: 0.213072\n",
      "[5]\tvalid_0's multi_logloss: 0.21282\n",
      "[6]\tvalid_0's multi_logloss: 0.21238\n",
      "[7]\tvalid_0's multi_logloss: 0.21212\n",
      "[8]\tvalid_0's multi_logloss: 0.211931\n",
      "[9]\tvalid_0's multi_logloss: 0.211733\n",
      "[10]\tvalid_0's multi_logloss: 0.211496\n",
      "[11]\tvalid_0's multi_logloss: 0.211131\n",
      "[12]\tvalid_0's multi_logloss: 0.210951\n",
      "[13]\tvalid_0's multi_logloss: 0.211148\n",
      "[14]\tvalid_0's multi_logloss: 0.21122\n",
      "[15]\tvalid_0's multi_logloss: 0.211105\n",
      "[16]\tvalid_0's multi_logloss: 0.211112\n",
      "[17]\tvalid_0's multi_logloss: 0.211177\n",
      "[18]\tvalid_0's multi_logloss: 0.211093\n",
      "[19]\tvalid_0's multi_logloss: 0.211231\n",
      "[20]\tvalid_0's multi_logloss: 0.211362\n",
      "[21]\tvalid_0's multi_logloss: 0.211314\n",
      "[22]\tvalid_0's multi_logloss: 0.211646\n",
      "[23]\tvalid_0's multi_logloss: 0.211635\n",
      "[24]\tvalid_0's multi_logloss: 0.211656\n",
      "[25]\tvalid_0's multi_logloss: 0.211788\n",
      "[26]\tvalid_0's multi_logloss: 0.211791\n",
      "[27]\tvalid_0's multi_logloss: 0.211758\n",
      "[28]\tvalid_0's multi_logloss: 0.211909\n",
      "[29]\tvalid_0's multi_logloss: 0.211949\n",
      "[30]\tvalid_0's multi_logloss: 0.211847\n",
      "[31]\tvalid_0's multi_logloss: 0.211965\n",
      "[32]\tvalid_0's multi_logloss: 0.212071\n",
      "[33]\tvalid_0's multi_logloss: 0.212261\n",
      "[34]\tvalid_0's multi_logloss: 0.212112\n",
      "[35]\tvalid_0's multi_logloss: 0.212216\n",
      "[36]\tvalid_0's multi_logloss: 0.212169\n",
      "[37]\tvalid_0's multi_logloss: 0.212169\n",
      "[38]\tvalid_0's multi_logloss: 0.212455\n",
      "[39]\tvalid_0's multi_logloss: 0.212473\n",
      "[40]\tvalid_0's multi_logloss: 0.212306\n",
      "[41]\tvalid_0's multi_logloss: 0.212472\n",
      "[42]\tvalid_0's multi_logloss: 0.212495\n",
      "[43]\tvalid_0's multi_logloss: 0.212548\n",
      "[44]\tvalid_0's multi_logloss: 0.212727\n",
      "[45]\tvalid_0's multi_logloss: 0.212593\n",
      "[46]\tvalid_0's multi_logloss: 0.21259\n",
      "[47]\tvalid_0's multi_logloss: 0.21277\n",
      "[48]\tvalid_0's multi_logloss: 0.213358\n",
      "[49]\tvalid_0's multi_logloss: 0.213587\n",
      "[50]\tvalid_0's multi_logloss: 0.213705\n",
      "[51]\tvalid_0's multi_logloss: 0.213927\n",
      "[52]\tvalid_0's multi_logloss: 0.214081\n",
      "[53]\tvalid_0's multi_logloss: 0.214137\n",
      "[54]\tvalid_0's multi_logloss: 0.214414\n",
      "[55]\tvalid_0's multi_logloss: 0.214395\n",
      "[56]\tvalid_0's multi_logloss: 0.214338\n",
      "[57]\tvalid_0's multi_logloss: 0.214308\n",
      "[58]\tvalid_0's multi_logloss: 0.214205\n",
      "[59]\tvalid_0's multi_logloss: 0.214423\n",
      "[60]\tvalid_0's multi_logloss: 0.214802\n",
      "[61]\tvalid_0's multi_logloss: 0.214761\n",
      "[62]\tvalid_0's multi_logloss: 0.214901\n",
      "[63]\tvalid_0's multi_logloss: 0.214764\n",
      "[64]\tvalid_0's multi_logloss: 0.214837\n",
      "[65]\tvalid_0's multi_logloss: 0.215002\n",
      "[66]\tvalid_0's multi_logloss: 0.215073\n",
      "[67]\tvalid_0's multi_logloss: 0.214971\n",
      "[68]\tvalid_0's multi_logloss: 0.215174\n",
      "[69]\tvalid_0's multi_logloss: 0.215247\n",
      "[70]\tvalid_0's multi_logloss: 0.215478\n",
      "[71]\tvalid_0's multi_logloss: 0.215594\n",
      "[72]\tvalid_0's multi_logloss: 0.215605\n",
      "[73]\tvalid_0's multi_logloss: 0.215701\n",
      "[74]\tvalid_0's multi_logloss: 0.216041\n",
      "[75]\tvalid_0's multi_logloss: 0.216029\n",
      "[76]\tvalid_0's multi_logloss: 0.216376\n",
      "[77]\tvalid_0's multi_logloss: 0.216476\n",
      "[78]\tvalid_0's multi_logloss: 0.216922\n",
      "[79]\tvalid_0's multi_logloss: 0.217137\n",
      "[80]\tvalid_0's multi_logloss: 0.217113\n",
      "[81]\tvalid_0's multi_logloss: 0.21746\n",
      "[82]\tvalid_0's multi_logloss: 0.217754\n",
      "[83]\tvalid_0's multi_logloss: 0.217856\n",
      "[84]\tvalid_0's multi_logloss: 0.217859\n",
      "[85]\tvalid_0's multi_logloss: 0.218157\n",
      "[86]\tvalid_0's multi_logloss: 0.218644\n",
      "[87]\tvalid_0's multi_logloss: 0.218823\n",
      "[88]\tvalid_0's multi_logloss: 0.219142\n",
      "[89]\tvalid_0's multi_logloss: 0.219255\n",
      "[90]\tvalid_0's multi_logloss: 0.219334\n",
      "[91]\tvalid_0's multi_logloss: 0.219546\n",
      "[92]\tvalid_0's multi_logloss: 0.219846\n",
      "[93]\tvalid_0's multi_logloss: 0.219949\n",
      "[94]\tvalid_0's multi_logloss: 0.220359\n",
      "[95]\tvalid_0's multi_logloss: 0.220575\n",
      "[96]\tvalid_0's multi_logloss: 0.220798\n",
      "[97]\tvalid_0's multi_logloss: 0.221017\n",
      "[98]\tvalid_0's multi_logloss: 0.22122\n",
      "[99]\tvalid_0's multi_logloss: 0.221484\n",
      "[100]\tvalid_0's multi_logloss: 0.221648\n",
      "[101]\tvalid_0's multi_logloss: 0.221708\n",
      "[102]\tvalid_0's multi_logloss: 0.221914\n",
      "[103]\tvalid_0's multi_logloss: 0.222326\n",
      "[104]\tvalid_0's multi_logloss: 0.22243\n",
      "[105]\tvalid_0's multi_logloss: 0.222784\n",
      "[106]\tvalid_0's multi_logloss: 0.222875\n",
      "[107]\tvalid_0's multi_logloss: 0.22287\n",
      "[108]\tvalid_0's multi_logloss: 0.222809\n",
      "[109]\tvalid_0's multi_logloss: 0.223091\n",
      "[110]\tvalid_0's multi_logloss: 0.223288\n",
      "[111]\tvalid_0's multi_logloss: 0.223396\n",
      "[112]\tvalid_0's multi_logloss: 0.223689\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 0.210951\n",
      "AAAAAA (2000, 228)\n",
      "lgb now score is: [2.6300821660643603, 2.589485985152662, 2.5884166050143556, 2.5602029903385746, 2.631675586694978]\n",
      "lgb_score_list: [2.6300821660643603, 2.589485985152662, 2.5884166050143556, 2.5602029903385746, 2.631675586694978]\n",
      "lgb_score_mean: 2.599972666652986\n",
      "[0]\ttrain-mlogloss:0.67064\teval-mlogloss:0.67106\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.64975\teval-mlogloss:0.65085\n",
      "[2]\ttrain-mlogloss:0.62999\teval-mlogloss:0.63152\n",
      "[3]\ttrain-mlogloss:0.61123\teval-mlogloss:0.61327\n",
      "[4]\ttrain-mlogloss:0.59337\teval-mlogloss:0.59583\n",
      "[5]\ttrain-mlogloss:0.57651\teval-mlogloss:0.57930\n",
      "[6]\ttrain-mlogloss:0.56065\teval-mlogloss:0.56392\n",
      "[7]\ttrain-mlogloss:0.54529\teval-mlogloss:0.54908\n",
      "[8]\ttrain-mlogloss:0.53096\teval-mlogloss:0.53537\n",
      "[9]\ttrain-mlogloss:0.51708\teval-mlogloss:0.52177\n",
      "[10]\ttrain-mlogloss:0.50402\teval-mlogloss:0.50906\n",
      "[11]\ttrain-mlogloss:0.49155\teval-mlogloss:0.49699\n",
      "[12]\ttrain-mlogloss:0.47978\teval-mlogloss:0.48548\n",
      "[13]\ttrain-mlogloss:0.46857\teval-mlogloss:0.47473\n",
      "[14]\ttrain-mlogloss:0.45774\teval-mlogloss:0.46416\n",
      "[15]\ttrain-mlogloss:0.44771\teval-mlogloss:0.45462\n",
      "[16]\ttrain-mlogloss:0.43802\teval-mlogloss:0.44501\n",
      "[17]\ttrain-mlogloss:0.42865\teval-mlogloss:0.43604\n",
      "[18]\ttrain-mlogloss:0.41960\teval-mlogloss:0.42739\n",
      "[19]\ttrain-mlogloss:0.41087\teval-mlogloss:0.41900\n",
      "[20]\ttrain-mlogloss:0.40259\teval-mlogloss:0.41085\n",
      "[21]\ttrain-mlogloss:0.39484\teval-mlogloss:0.40343\n",
      "[22]\ttrain-mlogloss:0.38711\teval-mlogloss:0.39604\n",
      "[23]\ttrain-mlogloss:0.37989\teval-mlogloss:0.38906\n",
      "[24]\ttrain-mlogloss:0.37304\teval-mlogloss:0.38239\n",
      "[25]\ttrain-mlogloss:0.36640\teval-mlogloss:0.37632\n",
      "[26]\ttrain-mlogloss:0.35994\teval-mlogloss:0.37033\n",
      "[27]\ttrain-mlogloss:0.35377\teval-mlogloss:0.36445\n",
      "[28]\ttrain-mlogloss:0.34786\teval-mlogloss:0.35895\n",
      "[29]\ttrain-mlogloss:0.34229\teval-mlogloss:0.35367\n",
      "[30]\ttrain-mlogloss:0.33685\teval-mlogloss:0.34841\n",
      "[31]\ttrain-mlogloss:0.33175\teval-mlogloss:0.34364\n",
      "[32]\ttrain-mlogloss:0.32669\teval-mlogloss:0.33939\n",
      "[33]\ttrain-mlogloss:0.32187\teval-mlogloss:0.33517\n",
      "[34]\ttrain-mlogloss:0.31718\teval-mlogloss:0.33091\n",
      "[35]\ttrain-mlogloss:0.31267\teval-mlogloss:0.32677\n",
      "[36]\ttrain-mlogloss:0.30838\teval-mlogloss:0.32303\n",
      "[37]\ttrain-mlogloss:0.30435\teval-mlogloss:0.31939\n",
      "[38]\ttrain-mlogloss:0.30044\teval-mlogloss:0.31582\n",
      "[39]\ttrain-mlogloss:0.29667\teval-mlogloss:0.31230\n",
      "[40]\ttrain-mlogloss:0.29290\teval-mlogloss:0.30921\n",
      "[41]\ttrain-mlogloss:0.28921\teval-mlogloss:0.30590\n",
      "[42]\ttrain-mlogloss:0.28578\teval-mlogloss:0.30302\n",
      "[43]\ttrain-mlogloss:0.28238\teval-mlogloss:0.30026\n",
      "[44]\ttrain-mlogloss:0.27925\teval-mlogloss:0.29773\n",
      "[45]\ttrain-mlogloss:0.27610\teval-mlogloss:0.29482\n",
      "[46]\ttrain-mlogloss:0.27312\teval-mlogloss:0.29235\n",
      "[47]\ttrain-mlogloss:0.27011\teval-mlogloss:0.29009\n",
      "[48]\ttrain-mlogloss:0.26727\teval-mlogloss:0.28787\n",
      "[49]\ttrain-mlogloss:0.26459\teval-mlogloss:0.28568\n",
      "[50]\ttrain-mlogloss:0.26187\teval-mlogloss:0.28349\n",
      "[51]\ttrain-mlogloss:0.25923\teval-mlogloss:0.28155\n",
      "[52]\ttrain-mlogloss:0.25667\teval-mlogloss:0.27963\n",
      "[53]\ttrain-mlogloss:0.25412\teval-mlogloss:0.27793\n",
      "[54]\ttrain-mlogloss:0.25175\teval-mlogloss:0.27616\n",
      "[55]\ttrain-mlogloss:0.24961\teval-mlogloss:0.27463\n",
      "[56]\ttrain-mlogloss:0.24749\teval-mlogloss:0.27303\n",
      "[57]\ttrain-mlogloss:0.24526\teval-mlogloss:0.27158\n",
      "[58]\ttrain-mlogloss:0.24318\teval-mlogloss:0.27015\n",
      "[59]\ttrain-mlogloss:0.24125\teval-mlogloss:0.26885\n",
      "[60]\ttrain-mlogloss:0.23916\teval-mlogloss:0.26744\n",
      "[61]\ttrain-mlogloss:0.23717\teval-mlogloss:0.26613\n",
      "[62]\ttrain-mlogloss:0.23551\teval-mlogloss:0.26491\n",
      "[63]\ttrain-mlogloss:0.23352\teval-mlogloss:0.26361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64]\ttrain-mlogloss:0.23167\teval-mlogloss:0.26242\n",
      "[65]\ttrain-mlogloss:0.22967\teval-mlogloss:0.26134\n",
      "[66]\ttrain-mlogloss:0.22812\teval-mlogloss:0.26029\n",
      "[67]\ttrain-mlogloss:0.22635\teval-mlogloss:0.25960\n",
      "[68]\ttrain-mlogloss:0.22458\teval-mlogloss:0.25900\n",
      "[69]\ttrain-mlogloss:0.22299\teval-mlogloss:0.25815\n",
      "[70]\ttrain-mlogloss:0.22120\teval-mlogloss:0.25724\n",
      "[71]\ttrain-mlogloss:0.21974\teval-mlogloss:0.25638\n",
      "[72]\ttrain-mlogloss:0.21819\teval-mlogloss:0.25561\n",
      "[73]\ttrain-mlogloss:0.21667\teval-mlogloss:0.25488\n",
      "[74]\ttrain-mlogloss:0.21517\teval-mlogloss:0.25410\n",
      "[75]\ttrain-mlogloss:0.21380\teval-mlogloss:0.25343\n",
      "[76]\ttrain-mlogloss:0.21239\teval-mlogloss:0.25286\n",
      "[77]\ttrain-mlogloss:0.21126\teval-mlogloss:0.25230\n",
      "[78]\ttrain-mlogloss:0.20988\teval-mlogloss:0.25182\n",
      "[79]\ttrain-mlogloss:0.20878\teval-mlogloss:0.25131\n",
      "[80]\ttrain-mlogloss:0.20767\teval-mlogloss:0.25060\n",
      "[81]\ttrain-mlogloss:0.20650\teval-mlogloss:0.25013\n",
      "[82]\ttrain-mlogloss:0.20544\teval-mlogloss:0.24964\n",
      "[83]\ttrain-mlogloss:0.20425\teval-mlogloss:0.24919\n",
      "[84]\ttrain-mlogloss:0.20300\teval-mlogloss:0.24876\n",
      "[85]\ttrain-mlogloss:0.20177\teval-mlogloss:0.24835\n",
      "[86]\ttrain-mlogloss:0.20069\teval-mlogloss:0.24799\n",
      "[87]\ttrain-mlogloss:0.19959\teval-mlogloss:0.24777\n",
      "[88]\ttrain-mlogloss:0.19827\teval-mlogloss:0.24774\n",
      "[89]\ttrain-mlogloss:0.19712\teval-mlogloss:0.24736\n",
      "[90]\ttrain-mlogloss:0.19584\teval-mlogloss:0.24712\n",
      "[91]\ttrain-mlogloss:0.19485\teval-mlogloss:0.24680\n",
      "[92]\ttrain-mlogloss:0.19392\teval-mlogloss:0.24661\n",
      "[93]\ttrain-mlogloss:0.19276\teval-mlogloss:0.24639\n",
      "[94]\ttrain-mlogloss:0.19179\teval-mlogloss:0.24618\n",
      "[95]\ttrain-mlogloss:0.19077\teval-mlogloss:0.24604\n",
      "[96]\ttrain-mlogloss:0.18992\teval-mlogloss:0.24587\n",
      "[97]\ttrain-mlogloss:0.18888\teval-mlogloss:0.24572\n",
      "[98]\ttrain-mlogloss:0.18789\teval-mlogloss:0.24554\n",
      "[99]\ttrain-mlogloss:0.18693\teval-mlogloss:0.24536\n",
      "[100]\ttrain-mlogloss:0.18609\teval-mlogloss:0.24509\n",
      "[101]\ttrain-mlogloss:0.18525\teval-mlogloss:0.24499\n",
      "[102]\ttrain-mlogloss:0.18443\teval-mlogloss:0.24469\n",
      "[103]\ttrain-mlogloss:0.18354\teval-mlogloss:0.24455\n",
      "[104]\ttrain-mlogloss:0.18257\teval-mlogloss:0.24467\n",
      "[105]\ttrain-mlogloss:0.18186\teval-mlogloss:0.24445\n",
      "[106]\ttrain-mlogloss:0.18087\teval-mlogloss:0.24429\n",
      "[107]\ttrain-mlogloss:0.18008\teval-mlogloss:0.24425\n",
      "[108]\ttrain-mlogloss:0.17934\teval-mlogloss:0.24446\n",
      "[109]\ttrain-mlogloss:0.17853\teval-mlogloss:0.24464\n",
      "[110]\ttrain-mlogloss:0.17746\teval-mlogloss:0.24469\n",
      "[111]\ttrain-mlogloss:0.17654\teval-mlogloss:0.24487\n",
      "[112]\ttrain-mlogloss:0.17560\teval-mlogloss:0.24481\n",
      "[113]\ttrain-mlogloss:0.17470\teval-mlogloss:0.24480\n",
      "[114]\ttrain-mlogloss:0.17382\teval-mlogloss:0.24496\n",
      "[115]\ttrain-mlogloss:0.17293\teval-mlogloss:0.24480\n",
      "[116]\ttrain-mlogloss:0.17201\teval-mlogloss:0.24483\n",
      "[117]\ttrain-mlogloss:0.17116\teval-mlogloss:0.24509\n",
      "[118]\ttrain-mlogloss:0.17039\teval-mlogloss:0.24522\n",
      "[119]\ttrain-mlogloss:0.16955\teval-mlogloss:0.24520\n",
      "[120]\ttrain-mlogloss:0.16869\teval-mlogloss:0.24527\n",
      "[121]\ttrain-mlogloss:0.16794\teval-mlogloss:0.24525\n",
      "[122]\ttrain-mlogloss:0.16720\teval-mlogloss:0.24551\n",
      "[123]\ttrain-mlogloss:0.16624\teval-mlogloss:0.24546\n",
      "[124]\ttrain-mlogloss:0.16552\teval-mlogloss:0.24544\n",
      "[125]\ttrain-mlogloss:0.16469\teval-mlogloss:0.24543\n",
      "[126]\ttrain-mlogloss:0.16397\teval-mlogloss:0.24549\n",
      "[127]\ttrain-mlogloss:0.16327\teval-mlogloss:0.24571\n",
      "[128]\ttrain-mlogloss:0.16275\teval-mlogloss:0.24596\n",
      "[129]\ttrain-mlogloss:0.16195\teval-mlogloss:0.24586\n",
      "[130]\ttrain-mlogloss:0.16133\teval-mlogloss:0.24594\n",
      "[131]\ttrain-mlogloss:0.16070\teval-mlogloss:0.24612\n",
      "[132]\ttrain-mlogloss:0.15998\teval-mlogloss:0.24607\n",
      "[133]\ttrain-mlogloss:0.15921\teval-mlogloss:0.24603\n",
      "[134]\ttrain-mlogloss:0.15850\teval-mlogloss:0.24632\n",
      "[135]\ttrain-mlogloss:0.15779\teval-mlogloss:0.24640\n",
      "[136]\ttrain-mlogloss:0.15713\teval-mlogloss:0.24671\n",
      "[137]\ttrain-mlogloss:0.15653\teval-mlogloss:0.24701\n",
      "[138]\ttrain-mlogloss:0.15581\teval-mlogloss:0.24719\n",
      "[139]\ttrain-mlogloss:0.15526\teval-mlogloss:0.24711\n",
      "[140]\ttrain-mlogloss:0.15462\teval-mlogloss:0.24732\n",
      "[141]\ttrain-mlogloss:0.15393\teval-mlogloss:0.24727\n",
      "[142]\ttrain-mlogloss:0.15322\teval-mlogloss:0.24735\n",
      "[143]\ttrain-mlogloss:0.15242\teval-mlogloss:0.24730\n",
      "[144]\ttrain-mlogloss:0.15180\teval-mlogloss:0.24735\n",
      "[145]\ttrain-mlogloss:0.15124\teval-mlogloss:0.24757\n",
      "[146]\ttrain-mlogloss:0.15066\teval-mlogloss:0.24732\n",
      "[147]\ttrain-mlogloss:0.15007\teval-mlogloss:0.24723\n",
      "[148]\ttrain-mlogloss:0.14954\teval-mlogloss:0.24710\n",
      "[149]\ttrain-mlogloss:0.14900\teval-mlogloss:0.24744\n",
      "[150]\ttrain-mlogloss:0.14840\teval-mlogloss:0.24760\n",
      "[151]\ttrain-mlogloss:0.14795\teval-mlogloss:0.24787\n",
      "[152]\ttrain-mlogloss:0.14732\teval-mlogloss:0.24798\n",
      "[153]\ttrain-mlogloss:0.14658\teval-mlogloss:0.24817\n",
      "[154]\ttrain-mlogloss:0.14596\teval-mlogloss:0.24844\n",
      "[155]\ttrain-mlogloss:0.14525\teval-mlogloss:0.24847\n",
      "[156]\ttrain-mlogloss:0.14461\teval-mlogloss:0.24852\n",
      "[157]\ttrain-mlogloss:0.14413\teval-mlogloss:0.24864\n",
      "[158]\ttrain-mlogloss:0.14361\teval-mlogloss:0.24878\n",
      "[159]\ttrain-mlogloss:0.14311\teval-mlogloss:0.24892\n",
      "[160]\ttrain-mlogloss:0.14253\teval-mlogloss:0.24893\n",
      "[161]\ttrain-mlogloss:0.14203\teval-mlogloss:0.24894\n",
      "[162]\ttrain-mlogloss:0.14156\teval-mlogloss:0.24929\n",
      "[163]\ttrain-mlogloss:0.14109\teval-mlogloss:0.24958\n",
      "[164]\ttrain-mlogloss:0.14048\teval-mlogloss:0.24974\n",
      "[165]\ttrain-mlogloss:0.14000\teval-mlogloss:0.24986\n",
      "[166]\ttrain-mlogloss:0.13934\teval-mlogloss:0.24985\n",
      "[167]\ttrain-mlogloss:0.13881\teval-mlogloss:0.24998\n",
      "[168]\ttrain-mlogloss:0.13813\teval-mlogloss:0.25021\n",
      "[169]\ttrain-mlogloss:0.13781\teval-mlogloss:0.25041\n",
      "[170]\ttrain-mlogloss:0.13728\teval-mlogloss:0.25051\n",
      "[171]\ttrain-mlogloss:0.13679\teval-mlogloss:0.25070\n",
      "[172]\ttrain-mlogloss:0.13637\teval-mlogloss:0.25095\n",
      "[173]\ttrain-mlogloss:0.13579\teval-mlogloss:0.25084\n",
      "[174]\ttrain-mlogloss:0.13529\teval-mlogloss:0.25079\n",
      "[175]\ttrain-mlogloss:0.13477\teval-mlogloss:0.25083\n",
      "[176]\ttrain-mlogloss:0.13430\teval-mlogloss:0.25093\n",
      "[177]\ttrain-mlogloss:0.13379\teval-mlogloss:0.25122\n",
      "[178]\ttrain-mlogloss:0.13335\teval-mlogloss:0.25103\n",
      "[179]\ttrain-mlogloss:0.13286\teval-mlogloss:0.25127\n",
      "[180]\ttrain-mlogloss:0.13246\teval-mlogloss:0.25131\n",
      "[181]\ttrain-mlogloss:0.13199\teval-mlogloss:0.25157\n",
      "[182]\ttrain-mlogloss:0.13152\teval-mlogloss:0.25167\n",
      "[183]\ttrain-mlogloss:0.13098\teval-mlogloss:0.25176\n",
      "[184]\ttrain-mlogloss:0.13061\teval-mlogloss:0.25193\n",
      "[185]\ttrain-mlogloss:0.13017\teval-mlogloss:0.25218\n",
      "[186]\ttrain-mlogloss:0.12970\teval-mlogloss:0.25215\n",
      "[187]\ttrain-mlogloss:0.12921\teval-mlogloss:0.25240\n",
      "[188]\ttrain-mlogloss:0.12878\teval-mlogloss:0.25262\n",
      "[189]\ttrain-mlogloss:0.12843\teval-mlogloss:0.25266\n",
      "[190]\ttrain-mlogloss:0.12805\teval-mlogloss:0.25271\n",
      "[191]\ttrain-mlogloss:0.12772\teval-mlogloss:0.25288\n",
      "[192]\ttrain-mlogloss:0.12735\teval-mlogloss:0.25313\n",
      "[193]\ttrain-mlogloss:0.12696\teval-mlogloss:0.25329\n",
      "[194]\ttrain-mlogloss:0.12651\teval-mlogloss:0.25334\n",
      "[195]\ttrain-mlogloss:0.12610\teval-mlogloss:0.25348\n",
      "[196]\ttrain-mlogloss:0.12576\teval-mlogloss:0.25376\n",
      "[197]\ttrain-mlogloss:0.12541\teval-mlogloss:0.25377\n",
      "[198]\ttrain-mlogloss:0.12504\teval-mlogloss:0.25383\n",
      "[199]\ttrain-mlogloss:0.12472\teval-mlogloss:0.25410\n",
      "[200]\ttrain-mlogloss:0.12431\teval-mlogloss:0.25410\n",
      "[201]\ttrain-mlogloss:0.12394\teval-mlogloss:0.25424\n",
      "[202]\ttrain-mlogloss:0.12353\teval-mlogloss:0.25435\n",
      "[203]\ttrain-mlogloss:0.12319\teval-mlogloss:0.25448\n",
      "[204]\ttrain-mlogloss:0.12282\teval-mlogloss:0.25443\n",
      "[205]\ttrain-mlogloss:0.12244\teval-mlogloss:0.25437\n",
      "[206]\ttrain-mlogloss:0.12207\teval-mlogloss:0.25434\n",
      "[207]\ttrain-mlogloss:0.12180\teval-mlogloss:0.25432\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-mlogloss:0.18008\teval-mlogloss:0.24425\n",
      "\n",
      "xgb now score is: [2.4266696114931254]\n",
      "[0]\ttrain-mlogloss:0.67052\teval-mlogloss:0.67207\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.64896\teval-mlogloss:0.65188\n",
      "[2]\ttrain-mlogloss:0.62901\teval-mlogloss:0.63351\n",
      "[3]\ttrain-mlogloss:0.60992\teval-mlogloss:0.61589\n",
      "[4]\ttrain-mlogloss:0.59178\teval-mlogloss:0.59898\n",
      "[5]\ttrain-mlogloss:0.57454\teval-mlogloss:0.58305\n",
      "[6]\ttrain-mlogloss:0.55831\teval-mlogloss:0.56811\n",
      "[7]\ttrain-mlogloss:0.54275\teval-mlogloss:0.55388\n",
      "[8]\ttrain-mlogloss:0.52791\teval-mlogloss:0.54033\n",
      "[9]\ttrain-mlogloss:0.51390\teval-mlogloss:0.52742\n",
      "[10]\ttrain-mlogloss:0.50093\teval-mlogloss:0.51586\n",
      "[11]\ttrain-mlogloss:0.48805\teval-mlogloss:0.50421\n",
      "[12]\ttrain-mlogloss:0.47594\teval-mlogloss:0.49348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-mlogloss:0.46440\teval-mlogloss:0.48307\n",
      "[14]\ttrain-mlogloss:0.45346\teval-mlogloss:0.47330\n",
      "[15]\ttrain-mlogloss:0.44303\teval-mlogloss:0.46425\n",
      "[16]\ttrain-mlogloss:0.43307\teval-mlogloss:0.45518\n",
      "[17]\ttrain-mlogloss:0.42345\teval-mlogloss:0.44666\n",
      "[18]\ttrain-mlogloss:0.41418\teval-mlogloss:0.43869\n",
      "[19]\ttrain-mlogloss:0.40532\teval-mlogloss:0.43080\n",
      "[20]\ttrain-mlogloss:0.39686\teval-mlogloss:0.42342\n",
      "[21]\ttrain-mlogloss:0.38877\teval-mlogloss:0.41651\n",
      "[22]\ttrain-mlogloss:0.38125\teval-mlogloss:0.40980\n",
      "[23]\ttrain-mlogloss:0.37395\teval-mlogloss:0.40337\n",
      "[24]\ttrain-mlogloss:0.36702\teval-mlogloss:0.39733\n",
      "[25]\ttrain-mlogloss:0.36025\teval-mlogloss:0.39155\n",
      "[26]\ttrain-mlogloss:0.35367\teval-mlogloss:0.38595\n",
      "[27]\ttrain-mlogloss:0.34747\teval-mlogloss:0.38087\n",
      "[28]\ttrain-mlogloss:0.34134\teval-mlogloss:0.37584\n",
      "[29]\ttrain-mlogloss:0.33556\teval-mlogloss:0.37116\n",
      "[30]\ttrain-mlogloss:0.32976\teval-mlogloss:0.36650\n",
      "[31]\ttrain-mlogloss:0.32430\teval-mlogloss:0.36229\n",
      "[32]\ttrain-mlogloss:0.31913\teval-mlogloss:0.35803\n",
      "[33]\ttrain-mlogloss:0.31417\teval-mlogloss:0.35413\n",
      "[34]\ttrain-mlogloss:0.30942\teval-mlogloss:0.35034\n",
      "[35]\ttrain-mlogloss:0.30485\teval-mlogloss:0.34711\n",
      "[36]\ttrain-mlogloss:0.30043\teval-mlogloss:0.34357\n",
      "[37]\ttrain-mlogloss:0.29604\teval-mlogloss:0.34042\n",
      "[38]\ttrain-mlogloss:0.29193\teval-mlogloss:0.33747\n",
      "[39]\ttrain-mlogloss:0.28787\teval-mlogloss:0.33441\n",
      "[40]\ttrain-mlogloss:0.28412\teval-mlogloss:0.33156\n",
      "[41]\ttrain-mlogloss:0.28049\teval-mlogloss:0.32903\n",
      "[42]\ttrain-mlogloss:0.27687\teval-mlogloss:0.32654\n",
      "[43]\ttrain-mlogloss:0.27343\teval-mlogloss:0.32441\n",
      "[44]\ttrain-mlogloss:0.26990\teval-mlogloss:0.32236\n",
      "[45]\ttrain-mlogloss:0.26652\teval-mlogloss:0.32014\n",
      "[46]\ttrain-mlogloss:0.26339\teval-mlogloss:0.31823\n",
      "[47]\ttrain-mlogloss:0.26037\teval-mlogloss:0.31624\n",
      "[48]\ttrain-mlogloss:0.25749\teval-mlogloss:0.31438\n",
      "[49]\ttrain-mlogloss:0.25472\teval-mlogloss:0.31275\n",
      "[50]\ttrain-mlogloss:0.25196\teval-mlogloss:0.31124\n",
      "[51]\ttrain-mlogloss:0.24941\teval-mlogloss:0.30976\n",
      "[52]\ttrain-mlogloss:0.24695\teval-mlogloss:0.30830\n",
      "[53]\ttrain-mlogloss:0.24446\teval-mlogloss:0.30673\n",
      "[54]\ttrain-mlogloss:0.24189\teval-mlogloss:0.30556\n",
      "[55]\ttrain-mlogloss:0.23958\teval-mlogloss:0.30438\n",
      "[56]\ttrain-mlogloss:0.23740\teval-mlogloss:0.30338\n",
      "[57]\ttrain-mlogloss:0.23528\teval-mlogloss:0.30232\n",
      "[58]\ttrain-mlogloss:0.23323\teval-mlogloss:0.30100\n",
      "[59]\ttrain-mlogloss:0.23115\teval-mlogloss:0.29994\n",
      "[60]\ttrain-mlogloss:0.22924\teval-mlogloss:0.29912\n",
      "[61]\ttrain-mlogloss:0.22728\teval-mlogloss:0.29830\n",
      "[62]\ttrain-mlogloss:0.22562\teval-mlogloss:0.29728\n",
      "[63]\ttrain-mlogloss:0.22366\teval-mlogloss:0.29637\n",
      "[64]\ttrain-mlogloss:0.22190\teval-mlogloss:0.29572\n",
      "[65]\ttrain-mlogloss:0.22017\teval-mlogloss:0.29513\n",
      "[66]\ttrain-mlogloss:0.21863\teval-mlogloss:0.29436\n",
      "[67]\ttrain-mlogloss:0.21674\teval-mlogloss:0.29389\n",
      "[68]\ttrain-mlogloss:0.21499\teval-mlogloss:0.29341\n",
      "[69]\ttrain-mlogloss:0.21334\teval-mlogloss:0.29285\n",
      "[70]\ttrain-mlogloss:0.21177\teval-mlogloss:0.29214\n",
      "[71]\ttrain-mlogloss:0.21028\teval-mlogloss:0.29162\n",
      "[72]\ttrain-mlogloss:0.20882\teval-mlogloss:0.29130\n",
      "[73]\ttrain-mlogloss:0.20708\teval-mlogloss:0.29084\n",
      "[74]\ttrain-mlogloss:0.20555\teval-mlogloss:0.29058\n",
      "[75]\ttrain-mlogloss:0.20399\teval-mlogloss:0.29015\n",
      "[76]\ttrain-mlogloss:0.20264\teval-mlogloss:0.28985\n",
      "[77]\ttrain-mlogloss:0.20146\teval-mlogloss:0.28959\n",
      "[78]\ttrain-mlogloss:0.20012\teval-mlogloss:0.28946\n",
      "[79]\ttrain-mlogloss:0.19889\teval-mlogloss:0.28922\n",
      "[80]\ttrain-mlogloss:0.19750\teval-mlogloss:0.28933\n",
      "[81]\ttrain-mlogloss:0.19619\teval-mlogloss:0.28937\n",
      "[82]\ttrain-mlogloss:0.19480\teval-mlogloss:0.28907\n",
      "[83]\ttrain-mlogloss:0.19354\teval-mlogloss:0.28896\n",
      "[84]\ttrain-mlogloss:0.19214\teval-mlogloss:0.28870\n",
      "[85]\ttrain-mlogloss:0.19110\teval-mlogloss:0.28880\n",
      "[86]\ttrain-mlogloss:0.18993\teval-mlogloss:0.28898\n",
      "[87]\ttrain-mlogloss:0.18899\teval-mlogloss:0.28900\n",
      "[88]\ttrain-mlogloss:0.18797\teval-mlogloss:0.28908\n",
      "[89]\ttrain-mlogloss:0.18683\teval-mlogloss:0.28914\n",
      "[90]\ttrain-mlogloss:0.18560\teval-mlogloss:0.28919\n",
      "[91]\ttrain-mlogloss:0.18450\teval-mlogloss:0.28932\n",
      "[92]\ttrain-mlogloss:0.18353\teval-mlogloss:0.28959\n",
      "[93]\ttrain-mlogloss:0.18232\teval-mlogloss:0.28955\n",
      "[94]\ttrain-mlogloss:0.18112\teval-mlogloss:0.28967\n",
      "[95]\ttrain-mlogloss:0.18005\teval-mlogloss:0.28976\n",
      "[96]\ttrain-mlogloss:0.17897\teval-mlogloss:0.28972\n",
      "[97]\ttrain-mlogloss:0.17799\teval-mlogloss:0.29001\n",
      "[98]\ttrain-mlogloss:0.17693\teval-mlogloss:0.29023\n",
      "[99]\ttrain-mlogloss:0.17593\teval-mlogloss:0.29030\n",
      "[100]\ttrain-mlogloss:0.17493\teval-mlogloss:0.29058\n",
      "[101]\ttrain-mlogloss:0.17383\teval-mlogloss:0.29046\n",
      "[102]\ttrain-mlogloss:0.17288\teval-mlogloss:0.29081\n",
      "[103]\ttrain-mlogloss:0.17202\teval-mlogloss:0.29094\n",
      "[104]\ttrain-mlogloss:0.17109\teval-mlogloss:0.29135\n",
      "[105]\ttrain-mlogloss:0.17025\teval-mlogloss:0.29159\n",
      "[106]\ttrain-mlogloss:0.16937\teval-mlogloss:0.29197\n",
      "[107]\ttrain-mlogloss:0.16846\teval-mlogloss:0.29226\n",
      "[108]\ttrain-mlogloss:0.16745\teval-mlogloss:0.29242\n",
      "[109]\ttrain-mlogloss:0.16663\teval-mlogloss:0.29272\n",
      "[110]\ttrain-mlogloss:0.16567\teval-mlogloss:0.29286\n",
      "[111]\ttrain-mlogloss:0.16500\teval-mlogloss:0.29296\n",
      "[112]\ttrain-mlogloss:0.16432\teval-mlogloss:0.29315\n",
      "[113]\ttrain-mlogloss:0.16359\teval-mlogloss:0.29344\n",
      "[114]\ttrain-mlogloss:0.16272\teval-mlogloss:0.29366\n",
      "[115]\ttrain-mlogloss:0.16184\teval-mlogloss:0.29394\n",
      "[116]\ttrain-mlogloss:0.16107\teval-mlogloss:0.29422\n",
      "[117]\ttrain-mlogloss:0.16033\teval-mlogloss:0.29441\n",
      "[118]\ttrain-mlogloss:0.15962\teval-mlogloss:0.29466\n",
      "[119]\ttrain-mlogloss:0.15880\teval-mlogloss:0.29479\n",
      "[120]\ttrain-mlogloss:0.15808\teval-mlogloss:0.29490\n",
      "[121]\ttrain-mlogloss:0.15740\teval-mlogloss:0.29490\n",
      "[122]\ttrain-mlogloss:0.15669\teval-mlogloss:0.29501\n",
      "[123]\ttrain-mlogloss:0.15602\teval-mlogloss:0.29500\n",
      "[124]\ttrain-mlogloss:0.15544\teval-mlogloss:0.29519\n",
      "[125]\ttrain-mlogloss:0.15469\teval-mlogloss:0.29551\n",
      "[126]\ttrain-mlogloss:0.15404\teval-mlogloss:0.29568\n",
      "[127]\ttrain-mlogloss:0.15338\teval-mlogloss:0.29617\n",
      "[128]\ttrain-mlogloss:0.15265\teval-mlogloss:0.29605\n",
      "[129]\ttrain-mlogloss:0.15187\teval-mlogloss:0.29598\n",
      "[130]\ttrain-mlogloss:0.15126\teval-mlogloss:0.29605\n",
      "[131]\ttrain-mlogloss:0.15070\teval-mlogloss:0.29652\n",
      "[132]\ttrain-mlogloss:0.15010\teval-mlogloss:0.29685\n",
      "[133]\ttrain-mlogloss:0.14935\teval-mlogloss:0.29712\n",
      "[134]\ttrain-mlogloss:0.14860\teval-mlogloss:0.29762\n",
      "[135]\ttrain-mlogloss:0.14791\teval-mlogloss:0.29780\n",
      "[136]\ttrain-mlogloss:0.14744\teval-mlogloss:0.29818\n",
      "[137]\ttrain-mlogloss:0.14683\teval-mlogloss:0.29837\n",
      "[138]\ttrain-mlogloss:0.14616\teval-mlogloss:0.29871\n",
      "[139]\ttrain-mlogloss:0.14558\teval-mlogloss:0.29914\n",
      "[140]\ttrain-mlogloss:0.14493\teval-mlogloss:0.29946\n",
      "[141]\ttrain-mlogloss:0.14435\teval-mlogloss:0.29960\n",
      "[142]\ttrain-mlogloss:0.14373\teval-mlogloss:0.29960\n",
      "[143]\ttrain-mlogloss:0.14327\teval-mlogloss:0.29949\n",
      "[144]\ttrain-mlogloss:0.14270\teval-mlogloss:0.29982\n",
      "[145]\ttrain-mlogloss:0.14209\teval-mlogloss:0.30038\n",
      "[146]\ttrain-mlogloss:0.14148\teval-mlogloss:0.30082\n",
      "[147]\ttrain-mlogloss:0.14091\teval-mlogloss:0.30122\n",
      "[148]\ttrain-mlogloss:0.14036\teval-mlogloss:0.30159\n",
      "[149]\ttrain-mlogloss:0.13984\teval-mlogloss:0.30191\n",
      "[150]\ttrain-mlogloss:0.13929\teval-mlogloss:0.30232\n",
      "[151]\ttrain-mlogloss:0.13862\teval-mlogloss:0.30260\n",
      "[152]\ttrain-mlogloss:0.13795\teval-mlogloss:0.30269\n",
      "[153]\ttrain-mlogloss:0.13745\teval-mlogloss:0.30293\n",
      "[154]\ttrain-mlogloss:0.13671\teval-mlogloss:0.30340\n",
      "[155]\ttrain-mlogloss:0.13622\teval-mlogloss:0.30390\n",
      "[156]\ttrain-mlogloss:0.13577\teval-mlogloss:0.30404\n",
      "[157]\ttrain-mlogloss:0.13521\teval-mlogloss:0.30429\n",
      "[158]\ttrain-mlogloss:0.13463\teval-mlogloss:0.30461\n",
      "[159]\ttrain-mlogloss:0.13413\teval-mlogloss:0.30486\n",
      "[160]\ttrain-mlogloss:0.13353\teval-mlogloss:0.30515\n",
      "[161]\ttrain-mlogloss:0.13311\teval-mlogloss:0.30526\n",
      "[162]\ttrain-mlogloss:0.13267\teval-mlogloss:0.30550\n",
      "[163]\ttrain-mlogloss:0.13219\teval-mlogloss:0.30587\n",
      "[164]\ttrain-mlogloss:0.13165\teval-mlogloss:0.30620\n",
      "[165]\ttrain-mlogloss:0.13120\teval-mlogloss:0.30645\n",
      "[166]\ttrain-mlogloss:0.13074\teval-mlogloss:0.30686\n",
      "[167]\ttrain-mlogloss:0.13026\teval-mlogloss:0.30709\n",
      "[168]\ttrain-mlogloss:0.12967\teval-mlogloss:0.30724\n",
      "[169]\ttrain-mlogloss:0.12912\teval-mlogloss:0.30766\n",
      "[170]\ttrain-mlogloss:0.12875\teval-mlogloss:0.30794\n",
      "[171]\ttrain-mlogloss:0.12830\teval-mlogloss:0.30808\n",
      "[172]\ttrain-mlogloss:0.12785\teval-mlogloss:0.30828\n",
      "[173]\ttrain-mlogloss:0.12739\teval-mlogloss:0.30837\n",
      "[174]\ttrain-mlogloss:0.12694\teval-mlogloss:0.30859\n",
      "[175]\ttrain-mlogloss:0.12644\teval-mlogloss:0.30888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176]\ttrain-mlogloss:0.12603\teval-mlogloss:0.30919\n",
      "[177]\ttrain-mlogloss:0.12568\teval-mlogloss:0.30918\n",
      "[178]\ttrain-mlogloss:0.12518\teval-mlogloss:0.30946\n",
      "[179]\ttrain-mlogloss:0.12480\teval-mlogloss:0.30981\n",
      "[180]\ttrain-mlogloss:0.12444\teval-mlogloss:0.30999\n",
      "[181]\ttrain-mlogloss:0.12401\teval-mlogloss:0.31006\n",
      "[182]\ttrain-mlogloss:0.12372\teval-mlogloss:0.31039\n",
      "[183]\ttrain-mlogloss:0.12339\teval-mlogloss:0.31088\n",
      "[184]\ttrain-mlogloss:0.12297\teval-mlogloss:0.31089\n",
      "Stopping. Best iteration:\n",
      "[84]\ttrain-mlogloss:0.19214\teval-mlogloss:0.28870\n",
      "\n",
      "xgb now score is: [2.4266696114931254, 2.207174352668226]\n",
      "[0]\ttrain-mlogloss:0.67046\teval-mlogloss:0.67131\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.64928\teval-mlogloss:0.65085\n",
      "[2]\ttrain-mlogloss:0.62932\teval-mlogloss:0.63174\n",
      "[3]\ttrain-mlogloss:0.61055\teval-mlogloss:0.61357\n",
      "[4]\ttrain-mlogloss:0.59260\teval-mlogloss:0.59651\n",
      "[5]\ttrain-mlogloss:0.57555\teval-mlogloss:0.58014\n",
      "[6]\ttrain-mlogloss:0.55962\teval-mlogloss:0.56475\n",
      "[7]\ttrain-mlogloss:0.54409\teval-mlogloss:0.55002\n",
      "[8]\ttrain-mlogloss:0.52926\teval-mlogloss:0.53584\n",
      "[9]\ttrain-mlogloss:0.51532\teval-mlogloss:0.52265\n",
      "[10]\ttrain-mlogloss:0.50219\teval-mlogloss:0.51014\n",
      "[11]\ttrain-mlogloss:0.48963\teval-mlogloss:0.49816\n",
      "[12]\ttrain-mlogloss:0.47783\teval-mlogloss:0.48687\n",
      "[13]\ttrain-mlogloss:0.46641\teval-mlogloss:0.47611\n",
      "[14]\ttrain-mlogloss:0.45554\teval-mlogloss:0.46582\n",
      "[15]\ttrain-mlogloss:0.44504\teval-mlogloss:0.45605\n",
      "[16]\ttrain-mlogloss:0.43505\teval-mlogloss:0.44674\n",
      "[17]\ttrain-mlogloss:0.42550\teval-mlogloss:0.43785\n",
      "[18]\ttrain-mlogloss:0.41644\teval-mlogloss:0.42972\n",
      "[19]\ttrain-mlogloss:0.40779\teval-mlogloss:0.42191\n",
      "[20]\ttrain-mlogloss:0.39939\teval-mlogloss:0.41434\n",
      "[21]\ttrain-mlogloss:0.39157\teval-mlogloss:0.40722\n",
      "[22]\ttrain-mlogloss:0.38389\teval-mlogloss:0.40022\n",
      "[23]\ttrain-mlogloss:0.37675\teval-mlogloss:0.39367\n",
      "[24]\ttrain-mlogloss:0.36983\teval-mlogloss:0.38738\n",
      "[25]\ttrain-mlogloss:0.36320\teval-mlogloss:0.38135\n",
      "[26]\ttrain-mlogloss:0.35684\teval-mlogloss:0.37547\n",
      "[27]\ttrain-mlogloss:0.35071\teval-mlogloss:0.36999\n",
      "[28]\ttrain-mlogloss:0.34477\teval-mlogloss:0.36475\n",
      "[29]\ttrain-mlogloss:0.33911\teval-mlogloss:0.35966\n",
      "[30]\ttrain-mlogloss:0.33347\teval-mlogloss:0.35492\n",
      "[31]\ttrain-mlogloss:0.32831\teval-mlogloss:0.35050\n",
      "[32]\ttrain-mlogloss:0.32325\teval-mlogloss:0.34612\n",
      "[33]\ttrain-mlogloss:0.31843\teval-mlogloss:0.34211\n",
      "[34]\ttrain-mlogloss:0.31372\teval-mlogloss:0.33789\n",
      "[35]\ttrain-mlogloss:0.30930\teval-mlogloss:0.33426\n",
      "[36]\ttrain-mlogloss:0.30491\teval-mlogloss:0.33071\n",
      "[37]\ttrain-mlogloss:0.30075\teval-mlogloss:0.32722\n",
      "[38]\ttrain-mlogloss:0.29674\teval-mlogloss:0.32404\n",
      "[39]\ttrain-mlogloss:0.29285\teval-mlogloss:0.32088\n",
      "[40]\ttrain-mlogloss:0.28923\teval-mlogloss:0.31793\n",
      "[41]\ttrain-mlogloss:0.28572\teval-mlogloss:0.31518\n",
      "[42]\ttrain-mlogloss:0.28233\teval-mlogloss:0.31238\n",
      "[43]\ttrain-mlogloss:0.27907\teval-mlogloss:0.30984\n",
      "[44]\ttrain-mlogloss:0.27581\teval-mlogloss:0.30739\n",
      "[45]\ttrain-mlogloss:0.27288\teval-mlogloss:0.30501\n",
      "[46]\ttrain-mlogloss:0.26992\teval-mlogloss:0.30291\n",
      "[47]\ttrain-mlogloss:0.26689\teval-mlogloss:0.30068\n",
      "[48]\ttrain-mlogloss:0.26398\teval-mlogloss:0.29846\n",
      "[49]\ttrain-mlogloss:0.26110\teval-mlogloss:0.29647\n",
      "[50]\ttrain-mlogloss:0.25838\teval-mlogloss:0.29454\n",
      "[51]\ttrain-mlogloss:0.25594\teval-mlogloss:0.29277\n",
      "[52]\ttrain-mlogloss:0.25339\teval-mlogloss:0.29078\n",
      "[53]\ttrain-mlogloss:0.25111\teval-mlogloss:0.28909\n",
      "[54]\ttrain-mlogloss:0.24876\teval-mlogloss:0.28749\n",
      "[55]\ttrain-mlogloss:0.24658\teval-mlogloss:0.28618\n",
      "[56]\ttrain-mlogloss:0.24445\teval-mlogloss:0.28472\n",
      "[57]\ttrain-mlogloss:0.24227\teval-mlogloss:0.28312\n",
      "[58]\ttrain-mlogloss:0.24011\teval-mlogloss:0.28177\n",
      "[59]\ttrain-mlogloss:0.23808\teval-mlogloss:0.28057\n",
      "[60]\ttrain-mlogloss:0.23628\teval-mlogloss:0.27950\n",
      "[61]\ttrain-mlogloss:0.23441\teval-mlogloss:0.27860\n",
      "[62]\ttrain-mlogloss:0.23271\teval-mlogloss:0.27753\n",
      "[63]\ttrain-mlogloss:0.23098\teval-mlogloss:0.27660\n",
      "[64]\ttrain-mlogloss:0.22917\teval-mlogloss:0.27547\n",
      "[65]\ttrain-mlogloss:0.22746\teval-mlogloss:0.27447\n",
      "[66]\ttrain-mlogloss:0.22597\teval-mlogloss:0.27367\n",
      "[67]\ttrain-mlogloss:0.22422\teval-mlogloss:0.27275\n",
      "[68]\ttrain-mlogloss:0.22282\teval-mlogloss:0.27206\n",
      "[69]\ttrain-mlogloss:0.22117\teval-mlogloss:0.27117\n",
      "[70]\ttrain-mlogloss:0.21953\teval-mlogloss:0.27075\n",
      "[71]\ttrain-mlogloss:0.21805\teval-mlogloss:0.27027\n",
      "[72]\ttrain-mlogloss:0.21660\teval-mlogloss:0.26973\n",
      "[73]\ttrain-mlogloss:0.21506\teval-mlogloss:0.26889\n",
      "[74]\ttrain-mlogloss:0.21355\teval-mlogloss:0.26822\n",
      "[75]\ttrain-mlogloss:0.21232\teval-mlogloss:0.26762\n",
      "[76]\ttrain-mlogloss:0.21082\teval-mlogloss:0.26722\n",
      "[77]\ttrain-mlogloss:0.20953\teval-mlogloss:0.26654\n",
      "[78]\ttrain-mlogloss:0.20822\teval-mlogloss:0.26614\n",
      "[79]\ttrain-mlogloss:0.20694\teval-mlogloss:0.26557\n",
      "[80]\ttrain-mlogloss:0.20584\teval-mlogloss:0.26519\n",
      "[81]\ttrain-mlogloss:0.20459\teval-mlogloss:0.26479\n",
      "[82]\ttrain-mlogloss:0.20325\teval-mlogloss:0.26432\n",
      "[83]\ttrain-mlogloss:0.20226\teval-mlogloss:0.26415\n",
      "[84]\ttrain-mlogloss:0.20109\teval-mlogloss:0.26393\n",
      "[85]\ttrain-mlogloss:0.19982\teval-mlogloss:0.26335\n",
      "[86]\ttrain-mlogloss:0.19853\teval-mlogloss:0.26278\n",
      "[87]\ttrain-mlogloss:0.19742\teval-mlogloss:0.26247\n",
      "[88]\ttrain-mlogloss:0.19646\teval-mlogloss:0.26230\n",
      "[89]\ttrain-mlogloss:0.19526\teval-mlogloss:0.26190\n",
      "[90]\ttrain-mlogloss:0.19410\teval-mlogloss:0.26180\n",
      "[91]\ttrain-mlogloss:0.19291\teval-mlogloss:0.26155\n",
      "[92]\ttrain-mlogloss:0.19195\teval-mlogloss:0.26136\n",
      "[93]\ttrain-mlogloss:0.19095\teval-mlogloss:0.26128\n",
      "[94]\ttrain-mlogloss:0.18986\teval-mlogloss:0.26118\n",
      "[95]\ttrain-mlogloss:0.18882\teval-mlogloss:0.26095\n",
      "[96]\ttrain-mlogloss:0.18784\teval-mlogloss:0.26098\n",
      "[97]\ttrain-mlogloss:0.18693\teval-mlogloss:0.26090\n",
      "[98]\ttrain-mlogloss:0.18613\teval-mlogloss:0.26088\n",
      "[99]\ttrain-mlogloss:0.18527\teval-mlogloss:0.26083\n",
      "[100]\ttrain-mlogloss:0.18424\teval-mlogloss:0.26079\n",
      "[101]\ttrain-mlogloss:0.18330\teval-mlogloss:0.26079\n",
      "[102]\ttrain-mlogloss:0.18237\teval-mlogloss:0.26081\n",
      "[103]\ttrain-mlogloss:0.18147\teval-mlogloss:0.26096\n",
      "[104]\ttrain-mlogloss:0.18052\teval-mlogloss:0.26081\n",
      "[105]\ttrain-mlogloss:0.17967\teval-mlogloss:0.26034\n",
      "[106]\ttrain-mlogloss:0.17877\teval-mlogloss:0.26017\n",
      "[107]\ttrain-mlogloss:0.17791\teval-mlogloss:0.26010\n",
      "[108]\ttrain-mlogloss:0.17719\teval-mlogloss:0.26028\n",
      "[109]\ttrain-mlogloss:0.17639\teval-mlogloss:0.26028\n",
      "[110]\ttrain-mlogloss:0.17559\teval-mlogloss:0.26049\n",
      "[111]\ttrain-mlogloss:0.17466\teval-mlogloss:0.26058\n",
      "[112]\ttrain-mlogloss:0.17383\teval-mlogloss:0.26046\n",
      "[113]\ttrain-mlogloss:0.17320\teval-mlogloss:0.26068\n",
      "[114]\ttrain-mlogloss:0.17228\teval-mlogloss:0.26064\n",
      "[115]\ttrain-mlogloss:0.17145\teval-mlogloss:0.26059\n",
      "[116]\ttrain-mlogloss:0.17075\teval-mlogloss:0.26041\n",
      "[117]\ttrain-mlogloss:0.16989\teval-mlogloss:0.26067\n",
      "[118]\ttrain-mlogloss:0.16907\teval-mlogloss:0.26085\n",
      "[119]\ttrain-mlogloss:0.16828\teval-mlogloss:0.26082\n",
      "[120]\ttrain-mlogloss:0.16747\teval-mlogloss:0.26080\n",
      "[121]\ttrain-mlogloss:0.16668\teval-mlogloss:0.26105\n",
      "[122]\ttrain-mlogloss:0.16598\teval-mlogloss:0.26092\n",
      "[123]\ttrain-mlogloss:0.16525\teval-mlogloss:0.26063\n",
      "[124]\ttrain-mlogloss:0.16453\teval-mlogloss:0.26064\n",
      "[125]\ttrain-mlogloss:0.16378\teval-mlogloss:0.26052\n",
      "[126]\ttrain-mlogloss:0.16326\teval-mlogloss:0.26058\n",
      "[127]\ttrain-mlogloss:0.16256\teval-mlogloss:0.26057\n",
      "[128]\ttrain-mlogloss:0.16198\teval-mlogloss:0.26058\n",
      "[129]\ttrain-mlogloss:0.16130\teval-mlogloss:0.26059\n",
      "[130]\ttrain-mlogloss:0.16070\teval-mlogloss:0.26050\n",
      "[131]\ttrain-mlogloss:0.15998\teval-mlogloss:0.26066\n",
      "[132]\ttrain-mlogloss:0.15929\teval-mlogloss:0.26091\n",
      "[133]\ttrain-mlogloss:0.15869\teval-mlogloss:0.26102\n",
      "[134]\ttrain-mlogloss:0.15817\teval-mlogloss:0.26129\n",
      "[135]\ttrain-mlogloss:0.15763\teval-mlogloss:0.26150\n",
      "[136]\ttrain-mlogloss:0.15708\teval-mlogloss:0.26159\n",
      "[137]\ttrain-mlogloss:0.15643\teval-mlogloss:0.26159\n",
      "[138]\ttrain-mlogloss:0.15574\teval-mlogloss:0.26184\n",
      "[139]\ttrain-mlogloss:0.15489\teval-mlogloss:0.26184\n",
      "[140]\ttrain-mlogloss:0.15421\teval-mlogloss:0.26205\n",
      "[141]\ttrain-mlogloss:0.15359\teval-mlogloss:0.26206\n",
      "[142]\ttrain-mlogloss:0.15297\teval-mlogloss:0.26203\n",
      "[143]\ttrain-mlogloss:0.15235\teval-mlogloss:0.26204\n",
      "[144]\ttrain-mlogloss:0.15183\teval-mlogloss:0.26225\n",
      "[145]\ttrain-mlogloss:0.15117\teval-mlogloss:0.26256\n",
      "[146]\ttrain-mlogloss:0.15063\teval-mlogloss:0.26304\n",
      "[147]\ttrain-mlogloss:0.15013\teval-mlogloss:0.26284\n",
      "[148]\ttrain-mlogloss:0.14945\teval-mlogloss:0.26277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149]\ttrain-mlogloss:0.14872\teval-mlogloss:0.26301\n",
      "[150]\ttrain-mlogloss:0.14797\teval-mlogloss:0.26341\n",
      "[151]\ttrain-mlogloss:0.14739\teval-mlogloss:0.26370\n",
      "[152]\ttrain-mlogloss:0.14687\teval-mlogloss:0.26386\n",
      "[153]\ttrain-mlogloss:0.14633\teval-mlogloss:0.26410\n",
      "[154]\ttrain-mlogloss:0.14580\teval-mlogloss:0.26393\n",
      "[155]\ttrain-mlogloss:0.14529\teval-mlogloss:0.26380\n",
      "[156]\ttrain-mlogloss:0.14464\teval-mlogloss:0.26376\n",
      "[157]\ttrain-mlogloss:0.14410\teval-mlogloss:0.26376\n",
      "[158]\ttrain-mlogloss:0.14349\teval-mlogloss:0.26398\n",
      "[159]\ttrain-mlogloss:0.14292\teval-mlogloss:0.26409\n",
      "[160]\ttrain-mlogloss:0.14245\teval-mlogloss:0.26407\n",
      "[161]\ttrain-mlogloss:0.14200\teval-mlogloss:0.26424\n",
      "[162]\ttrain-mlogloss:0.14143\teval-mlogloss:0.26427\n",
      "[163]\ttrain-mlogloss:0.14101\teval-mlogloss:0.26435\n",
      "[164]\ttrain-mlogloss:0.14048\teval-mlogloss:0.26444\n",
      "[165]\ttrain-mlogloss:0.13985\teval-mlogloss:0.26454\n",
      "[166]\ttrain-mlogloss:0.13931\teval-mlogloss:0.26477\n",
      "[167]\ttrain-mlogloss:0.13892\teval-mlogloss:0.26472\n",
      "[168]\ttrain-mlogloss:0.13845\teval-mlogloss:0.26467\n",
      "[169]\ttrain-mlogloss:0.13792\teval-mlogloss:0.26471\n",
      "[170]\ttrain-mlogloss:0.13741\teval-mlogloss:0.26458\n",
      "[171]\ttrain-mlogloss:0.13692\teval-mlogloss:0.26465\n",
      "[172]\ttrain-mlogloss:0.13650\teval-mlogloss:0.26448\n",
      "[173]\ttrain-mlogloss:0.13609\teval-mlogloss:0.26464\n",
      "[174]\ttrain-mlogloss:0.13557\teval-mlogloss:0.26464\n",
      "[175]\ttrain-mlogloss:0.13493\teval-mlogloss:0.26466\n",
      "[176]\ttrain-mlogloss:0.13440\teval-mlogloss:0.26480\n",
      "[177]\ttrain-mlogloss:0.13392\teval-mlogloss:0.26486\n",
      "[178]\ttrain-mlogloss:0.13339\teval-mlogloss:0.26478\n",
      "[179]\ttrain-mlogloss:0.13298\teval-mlogloss:0.26478\n",
      "[180]\ttrain-mlogloss:0.13247\teval-mlogloss:0.26503\n",
      "[181]\ttrain-mlogloss:0.13191\teval-mlogloss:0.26521\n",
      "[182]\ttrain-mlogloss:0.13143\teval-mlogloss:0.26532\n",
      "[183]\ttrain-mlogloss:0.13105\teval-mlogloss:0.26536\n",
      "[184]\ttrain-mlogloss:0.13062\teval-mlogloss:0.26541\n",
      "[185]\ttrain-mlogloss:0.13024\teval-mlogloss:0.26519\n",
      "[186]\ttrain-mlogloss:0.12980\teval-mlogloss:0.26526\n",
      "[187]\ttrain-mlogloss:0.12936\teval-mlogloss:0.26508\n",
      "[188]\ttrain-mlogloss:0.12894\teval-mlogloss:0.26498\n",
      "[189]\ttrain-mlogloss:0.12853\teval-mlogloss:0.26511\n",
      "[190]\ttrain-mlogloss:0.12810\teval-mlogloss:0.26513\n",
      "[191]\ttrain-mlogloss:0.12771\teval-mlogloss:0.26514\n",
      "[192]\ttrain-mlogloss:0.12725\teval-mlogloss:0.26530\n",
      "[193]\ttrain-mlogloss:0.12689\teval-mlogloss:0.26536\n",
      "[194]\ttrain-mlogloss:0.12653\teval-mlogloss:0.26547\n",
      "[195]\ttrain-mlogloss:0.12626\teval-mlogloss:0.26550\n",
      "[196]\ttrain-mlogloss:0.12595\teval-mlogloss:0.26537\n",
      "[197]\ttrain-mlogloss:0.12549\teval-mlogloss:0.26542\n",
      "[198]\ttrain-mlogloss:0.12509\teval-mlogloss:0.26571\n",
      "[199]\ttrain-mlogloss:0.12459\teval-mlogloss:0.26589\n",
      "[200]\ttrain-mlogloss:0.12426\teval-mlogloss:0.26609\n",
      "[201]\ttrain-mlogloss:0.12391\teval-mlogloss:0.26625\n",
      "[202]\ttrain-mlogloss:0.12357\teval-mlogloss:0.26641\n",
      "[203]\ttrain-mlogloss:0.12320\teval-mlogloss:0.26648\n",
      "[204]\ttrain-mlogloss:0.12280\teval-mlogloss:0.26660\n",
      "[205]\ttrain-mlogloss:0.12239\teval-mlogloss:0.26637\n",
      "[206]\ttrain-mlogloss:0.12202\teval-mlogloss:0.26643\n",
      "[207]\ttrain-mlogloss:0.12162\teval-mlogloss:0.26663\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-mlogloss:0.17791\teval-mlogloss:0.26010\n",
      "\n",
      "xgb now score is: [2.4266696114931254, 2.207174352668226, 2.4680812854133545]\n",
      "[0]\ttrain-mlogloss:0.67108\teval-mlogloss:0.67060\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.65029\teval-mlogloss:0.64929\n",
      "[2]\ttrain-mlogloss:0.63077\teval-mlogloss:0.62934\n",
      "[3]\ttrain-mlogloss:0.61233\teval-mlogloss:0.61058\n",
      "[4]\ttrain-mlogloss:0.59488\teval-mlogloss:0.59262\n",
      "[5]\ttrain-mlogloss:0.57832\teval-mlogloss:0.57562\n",
      "[6]\ttrain-mlogloss:0.56287\teval-mlogloss:0.55966\n",
      "[7]\ttrain-mlogloss:0.54793\teval-mlogloss:0.54459\n",
      "[8]\ttrain-mlogloss:0.53371\teval-mlogloss:0.53011\n",
      "[9]\ttrain-mlogloss:0.52018\teval-mlogloss:0.51625\n",
      "[10]\ttrain-mlogloss:0.50757\teval-mlogloss:0.50316\n",
      "[11]\ttrain-mlogloss:0.49544\teval-mlogloss:0.49062\n",
      "[12]\ttrain-mlogloss:0.48378\teval-mlogloss:0.47869\n",
      "[13]\ttrain-mlogloss:0.47283\teval-mlogloss:0.46741\n",
      "[14]\ttrain-mlogloss:0.46220\teval-mlogloss:0.45658\n",
      "[15]\ttrain-mlogloss:0.45227\teval-mlogloss:0.44634\n",
      "[16]\ttrain-mlogloss:0.44269\teval-mlogloss:0.43657\n",
      "[17]\ttrain-mlogloss:0.43353\teval-mlogloss:0.42737\n",
      "[18]\ttrain-mlogloss:0.42477\teval-mlogloss:0.41839\n",
      "[19]\ttrain-mlogloss:0.41638\teval-mlogloss:0.40985\n",
      "[20]\ttrain-mlogloss:0.40838\teval-mlogloss:0.40157\n",
      "[21]\ttrain-mlogloss:0.40060\teval-mlogloss:0.39364\n",
      "[22]\ttrain-mlogloss:0.39322\teval-mlogloss:0.38609\n",
      "[23]\ttrain-mlogloss:0.38607\teval-mlogloss:0.37856\n",
      "[24]\ttrain-mlogloss:0.37926\teval-mlogloss:0.37150\n",
      "[25]\ttrain-mlogloss:0.37269\teval-mlogloss:0.36488\n",
      "[26]\ttrain-mlogloss:0.36655\teval-mlogloss:0.35866\n",
      "[27]\ttrain-mlogloss:0.36057\teval-mlogloss:0.35248\n",
      "[28]\ttrain-mlogloss:0.35488\teval-mlogloss:0.34664\n",
      "[29]\ttrain-mlogloss:0.34950\teval-mlogloss:0.34107\n",
      "[30]\ttrain-mlogloss:0.34420\teval-mlogloss:0.33592\n",
      "[31]\ttrain-mlogloss:0.33922\teval-mlogloss:0.33066\n",
      "[32]\ttrain-mlogloss:0.33430\teval-mlogloss:0.32584\n",
      "[33]\ttrain-mlogloss:0.32971\teval-mlogloss:0.32098\n",
      "[34]\ttrain-mlogloss:0.32525\teval-mlogloss:0.31664\n",
      "[35]\ttrain-mlogloss:0.32079\teval-mlogloss:0.31208\n",
      "[36]\ttrain-mlogloss:0.31660\teval-mlogloss:0.30786\n",
      "[37]\ttrain-mlogloss:0.31271\teval-mlogloss:0.30411\n",
      "[38]\ttrain-mlogloss:0.30891\teval-mlogloss:0.30030\n",
      "[39]\ttrain-mlogloss:0.30514\teval-mlogloss:0.29637\n",
      "[40]\ttrain-mlogloss:0.30137\teval-mlogloss:0.29289\n",
      "[41]\ttrain-mlogloss:0.29801\teval-mlogloss:0.28941\n",
      "[42]\ttrain-mlogloss:0.29453\teval-mlogloss:0.28597\n",
      "[43]\ttrain-mlogloss:0.29124\teval-mlogloss:0.28264\n",
      "[44]\ttrain-mlogloss:0.28816\teval-mlogloss:0.27944\n",
      "[45]\ttrain-mlogloss:0.28502\teval-mlogloss:0.27634\n",
      "[46]\ttrain-mlogloss:0.28202\teval-mlogloss:0.27364\n",
      "[47]\ttrain-mlogloss:0.27913\teval-mlogloss:0.27090\n",
      "[48]\ttrain-mlogloss:0.27638\teval-mlogloss:0.26837\n",
      "[49]\ttrain-mlogloss:0.27373\teval-mlogloss:0.26580\n",
      "[50]\ttrain-mlogloss:0.27116\teval-mlogloss:0.26339\n",
      "[51]\ttrain-mlogloss:0.26873\teval-mlogloss:0.26106\n",
      "[52]\ttrain-mlogloss:0.26625\teval-mlogloss:0.25873\n",
      "[53]\ttrain-mlogloss:0.26387\teval-mlogloss:0.25667\n",
      "[54]\ttrain-mlogloss:0.26168\teval-mlogloss:0.25461\n",
      "[55]\ttrain-mlogloss:0.25940\teval-mlogloss:0.25273\n",
      "[56]\ttrain-mlogloss:0.25720\teval-mlogloss:0.25067\n",
      "[57]\ttrain-mlogloss:0.25502\teval-mlogloss:0.24889\n",
      "[58]\ttrain-mlogloss:0.25261\teval-mlogloss:0.24692\n",
      "[59]\ttrain-mlogloss:0.25059\teval-mlogloss:0.24526\n",
      "[60]\ttrain-mlogloss:0.24879\teval-mlogloss:0.24372\n",
      "[61]\ttrain-mlogloss:0.24690\teval-mlogloss:0.24203\n",
      "[62]\ttrain-mlogloss:0.24495\teval-mlogloss:0.24059\n",
      "[63]\ttrain-mlogloss:0.24334\teval-mlogloss:0.23909\n",
      "[64]\ttrain-mlogloss:0.24166\teval-mlogloss:0.23754\n",
      "[65]\ttrain-mlogloss:0.23996\teval-mlogloss:0.23612\n",
      "[66]\ttrain-mlogloss:0.23801\teval-mlogloss:0.23477\n",
      "[67]\ttrain-mlogloss:0.23625\teval-mlogloss:0.23358\n",
      "[68]\ttrain-mlogloss:0.23444\teval-mlogloss:0.23221\n",
      "[69]\ttrain-mlogloss:0.23284\teval-mlogloss:0.23122\n",
      "[70]\ttrain-mlogloss:0.23124\teval-mlogloss:0.23005\n",
      "[71]\ttrain-mlogloss:0.22975\teval-mlogloss:0.22902\n",
      "[72]\ttrain-mlogloss:0.22833\teval-mlogloss:0.22808\n",
      "[73]\ttrain-mlogloss:0.22678\teval-mlogloss:0.22712\n",
      "[74]\ttrain-mlogloss:0.22532\teval-mlogloss:0.22593\n",
      "[75]\ttrain-mlogloss:0.22377\teval-mlogloss:0.22508\n",
      "[76]\ttrain-mlogloss:0.22235\teval-mlogloss:0.22442\n",
      "[77]\ttrain-mlogloss:0.22092\teval-mlogloss:0.22368\n",
      "[78]\ttrain-mlogloss:0.21960\teval-mlogloss:0.22297\n",
      "[79]\ttrain-mlogloss:0.21830\teval-mlogloss:0.22200\n",
      "[80]\ttrain-mlogloss:0.21672\teval-mlogloss:0.22129\n",
      "[81]\ttrain-mlogloss:0.21551\teval-mlogloss:0.22030\n",
      "[82]\ttrain-mlogloss:0.21442\teval-mlogloss:0.21940\n",
      "[83]\ttrain-mlogloss:0.21322\teval-mlogloss:0.21860\n",
      "[84]\ttrain-mlogloss:0.21191\teval-mlogloss:0.21788\n",
      "[85]\ttrain-mlogloss:0.21079\teval-mlogloss:0.21742\n",
      "[86]\ttrain-mlogloss:0.20966\teval-mlogloss:0.21672\n",
      "[87]\ttrain-mlogloss:0.20828\teval-mlogloss:0.21615\n",
      "[88]\ttrain-mlogloss:0.20722\teval-mlogloss:0.21562\n",
      "[89]\ttrain-mlogloss:0.20599\teval-mlogloss:0.21521\n",
      "[90]\ttrain-mlogloss:0.20477\teval-mlogloss:0.21465\n",
      "[91]\ttrain-mlogloss:0.20356\teval-mlogloss:0.21415\n",
      "[92]\ttrain-mlogloss:0.20252\teval-mlogloss:0.21377\n",
      "[93]\ttrain-mlogloss:0.20153\teval-mlogloss:0.21346\n",
      "[94]\ttrain-mlogloss:0.20057\teval-mlogloss:0.21293\n",
      "[95]\ttrain-mlogloss:0.19942\teval-mlogloss:0.21255\n",
      "[96]\ttrain-mlogloss:0.19836\teval-mlogloss:0.21211\n",
      "[97]\ttrain-mlogloss:0.19728\teval-mlogloss:0.21181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\ttrain-mlogloss:0.19624\teval-mlogloss:0.21167\n",
      "[99]\ttrain-mlogloss:0.19523\teval-mlogloss:0.21124\n",
      "[100]\ttrain-mlogloss:0.19439\teval-mlogloss:0.21092\n",
      "[101]\ttrain-mlogloss:0.19342\teval-mlogloss:0.21074\n",
      "[102]\ttrain-mlogloss:0.19250\teval-mlogloss:0.21062\n",
      "[103]\ttrain-mlogloss:0.19152\teval-mlogloss:0.21022\n",
      "[104]\ttrain-mlogloss:0.19040\teval-mlogloss:0.20992\n",
      "[105]\ttrain-mlogloss:0.18952\teval-mlogloss:0.20985\n",
      "[106]\ttrain-mlogloss:0.18861\teval-mlogloss:0.20945\n",
      "[107]\ttrain-mlogloss:0.18769\teval-mlogloss:0.20930\n",
      "[108]\ttrain-mlogloss:0.18684\teval-mlogloss:0.20908\n",
      "[109]\ttrain-mlogloss:0.18588\teval-mlogloss:0.20904\n",
      "[110]\ttrain-mlogloss:0.18503\teval-mlogloss:0.20884\n",
      "[111]\ttrain-mlogloss:0.18394\teval-mlogloss:0.20854\n",
      "[112]\ttrain-mlogloss:0.18301\teval-mlogloss:0.20843\n",
      "[113]\ttrain-mlogloss:0.18224\teval-mlogloss:0.20836\n",
      "[114]\ttrain-mlogloss:0.18145\teval-mlogloss:0.20796\n",
      "[115]\ttrain-mlogloss:0.18050\teval-mlogloss:0.20766\n",
      "[116]\ttrain-mlogloss:0.17985\teval-mlogloss:0.20746\n",
      "[117]\ttrain-mlogloss:0.17902\teval-mlogloss:0.20737\n",
      "[118]\ttrain-mlogloss:0.17809\teval-mlogloss:0.20717\n",
      "[119]\ttrain-mlogloss:0.17727\teval-mlogloss:0.20694\n",
      "[120]\ttrain-mlogloss:0.17639\teval-mlogloss:0.20652\n",
      "[121]\ttrain-mlogloss:0.17561\teval-mlogloss:0.20630\n",
      "[122]\ttrain-mlogloss:0.17478\teval-mlogloss:0.20625\n",
      "[123]\ttrain-mlogloss:0.17400\teval-mlogloss:0.20618\n",
      "[124]\ttrain-mlogloss:0.17336\teval-mlogloss:0.20623\n",
      "[125]\ttrain-mlogloss:0.17272\teval-mlogloss:0.20599\n",
      "[126]\ttrain-mlogloss:0.17199\teval-mlogloss:0.20606\n",
      "[127]\ttrain-mlogloss:0.17120\teval-mlogloss:0.20602\n",
      "[128]\ttrain-mlogloss:0.17029\teval-mlogloss:0.20603\n",
      "[129]\ttrain-mlogloss:0.16939\teval-mlogloss:0.20561\n",
      "[130]\ttrain-mlogloss:0.16872\teval-mlogloss:0.20560\n",
      "[131]\ttrain-mlogloss:0.16795\teval-mlogloss:0.20586\n",
      "[132]\ttrain-mlogloss:0.16733\teval-mlogloss:0.20586\n",
      "[133]\ttrain-mlogloss:0.16670\teval-mlogloss:0.20567\n",
      "[134]\ttrain-mlogloss:0.16606\teval-mlogloss:0.20575\n",
      "[135]\ttrain-mlogloss:0.16529\teval-mlogloss:0.20579\n",
      "[136]\ttrain-mlogloss:0.16441\teval-mlogloss:0.20565\n",
      "[137]\ttrain-mlogloss:0.16369\teval-mlogloss:0.20574\n",
      "[138]\ttrain-mlogloss:0.16309\teval-mlogloss:0.20572\n",
      "[139]\ttrain-mlogloss:0.16246\teval-mlogloss:0.20545\n",
      "[140]\ttrain-mlogloss:0.16184\teval-mlogloss:0.20542\n",
      "[141]\ttrain-mlogloss:0.16128\teval-mlogloss:0.20555\n",
      "[142]\ttrain-mlogloss:0.16061\teval-mlogloss:0.20576\n",
      "[143]\ttrain-mlogloss:0.15990\teval-mlogloss:0.20566\n",
      "[144]\ttrain-mlogloss:0.15919\teval-mlogloss:0.20569\n",
      "[145]\ttrain-mlogloss:0.15867\teval-mlogloss:0.20572\n",
      "[146]\ttrain-mlogloss:0.15802\teval-mlogloss:0.20575\n",
      "[147]\ttrain-mlogloss:0.15734\teval-mlogloss:0.20564\n",
      "[148]\ttrain-mlogloss:0.15679\teval-mlogloss:0.20548\n",
      "[149]\ttrain-mlogloss:0.15621\teval-mlogloss:0.20556\n",
      "[150]\ttrain-mlogloss:0.15559\teval-mlogloss:0.20557\n",
      "[151]\ttrain-mlogloss:0.15488\teval-mlogloss:0.20560\n",
      "[152]\ttrain-mlogloss:0.15430\teval-mlogloss:0.20549\n",
      "[153]\ttrain-mlogloss:0.15383\teval-mlogloss:0.20554\n",
      "[154]\ttrain-mlogloss:0.15326\teval-mlogloss:0.20565\n",
      "[155]\ttrain-mlogloss:0.15264\teval-mlogloss:0.20576\n",
      "[156]\ttrain-mlogloss:0.15190\teval-mlogloss:0.20584\n",
      "[157]\ttrain-mlogloss:0.15127\teval-mlogloss:0.20589\n",
      "[158]\ttrain-mlogloss:0.15078\teval-mlogloss:0.20592\n",
      "[159]\ttrain-mlogloss:0.15027\teval-mlogloss:0.20596\n",
      "[160]\ttrain-mlogloss:0.14970\teval-mlogloss:0.20604\n",
      "[161]\ttrain-mlogloss:0.14917\teval-mlogloss:0.20584\n",
      "[162]\ttrain-mlogloss:0.14857\teval-mlogloss:0.20587\n",
      "[163]\ttrain-mlogloss:0.14807\teval-mlogloss:0.20586\n",
      "[164]\ttrain-mlogloss:0.14763\teval-mlogloss:0.20586\n",
      "[165]\ttrain-mlogloss:0.14714\teval-mlogloss:0.20600\n",
      "[166]\ttrain-mlogloss:0.14655\teval-mlogloss:0.20600\n",
      "[167]\ttrain-mlogloss:0.14605\teval-mlogloss:0.20616\n",
      "[168]\ttrain-mlogloss:0.14554\teval-mlogloss:0.20633\n",
      "[169]\ttrain-mlogloss:0.14494\teval-mlogloss:0.20613\n",
      "[170]\ttrain-mlogloss:0.14450\teval-mlogloss:0.20617\n",
      "[171]\ttrain-mlogloss:0.14399\teval-mlogloss:0.20646\n",
      "[172]\ttrain-mlogloss:0.14353\teval-mlogloss:0.20650\n",
      "[173]\ttrain-mlogloss:0.14315\teval-mlogloss:0.20672\n",
      "[174]\ttrain-mlogloss:0.14276\teval-mlogloss:0.20674\n",
      "[175]\ttrain-mlogloss:0.14231\teval-mlogloss:0.20670\n",
      "[176]\ttrain-mlogloss:0.14198\teval-mlogloss:0.20684\n",
      "[177]\ttrain-mlogloss:0.14153\teval-mlogloss:0.20682\n",
      "[178]\ttrain-mlogloss:0.14101\teval-mlogloss:0.20680\n",
      "[179]\ttrain-mlogloss:0.14051\teval-mlogloss:0.20708\n",
      "[180]\ttrain-mlogloss:0.14003\teval-mlogloss:0.20712\n",
      "[181]\ttrain-mlogloss:0.13960\teval-mlogloss:0.20721\n",
      "[182]\ttrain-mlogloss:0.13922\teval-mlogloss:0.20734\n",
      "[183]\ttrain-mlogloss:0.13880\teval-mlogloss:0.20720\n",
      "[184]\ttrain-mlogloss:0.13836\teval-mlogloss:0.20737\n",
      "[185]\ttrain-mlogloss:0.13788\teval-mlogloss:0.20732\n",
      "[186]\ttrain-mlogloss:0.13732\teval-mlogloss:0.20747\n",
      "[187]\ttrain-mlogloss:0.13690\teval-mlogloss:0.20757\n",
      "[188]\ttrain-mlogloss:0.13633\teval-mlogloss:0.20769\n",
      "[189]\ttrain-mlogloss:0.13591\teval-mlogloss:0.20771\n",
      "[190]\ttrain-mlogloss:0.13543\teval-mlogloss:0.20764\n",
      "[191]\ttrain-mlogloss:0.13499\teval-mlogloss:0.20780\n",
      "[192]\ttrain-mlogloss:0.13451\teval-mlogloss:0.20773\n",
      "[193]\ttrain-mlogloss:0.13419\teval-mlogloss:0.20779\n",
      "[194]\ttrain-mlogloss:0.13384\teval-mlogloss:0.20778\n",
      "[195]\ttrain-mlogloss:0.13342\teval-mlogloss:0.20784\n",
      "[196]\ttrain-mlogloss:0.13294\teval-mlogloss:0.20767\n",
      "[197]\ttrain-mlogloss:0.13255\teval-mlogloss:0.20761\n",
      "[198]\ttrain-mlogloss:0.13205\teval-mlogloss:0.20757\n",
      "[199]\ttrain-mlogloss:0.13164\teval-mlogloss:0.20763\n",
      "[200]\ttrain-mlogloss:0.13120\teval-mlogloss:0.20756\n",
      "[201]\ttrain-mlogloss:0.13079\teval-mlogloss:0.20767\n",
      "[202]\ttrain-mlogloss:0.13051\teval-mlogloss:0.20761\n",
      "[203]\ttrain-mlogloss:0.13006\teval-mlogloss:0.20769\n",
      "[204]\ttrain-mlogloss:0.12965\teval-mlogloss:0.20790\n",
      "[205]\ttrain-mlogloss:0.12924\teval-mlogloss:0.20787\n",
      "[206]\ttrain-mlogloss:0.12896\teval-mlogloss:0.20804\n",
      "[207]\ttrain-mlogloss:0.12859\teval-mlogloss:0.20812\n",
      "[208]\ttrain-mlogloss:0.12813\teval-mlogloss:0.20813\n",
      "[209]\ttrain-mlogloss:0.12774\teval-mlogloss:0.20808\n",
      "[210]\ttrain-mlogloss:0.12727\teval-mlogloss:0.20822\n",
      "[211]\ttrain-mlogloss:0.12688\teval-mlogloss:0.20845\n",
      "[212]\ttrain-mlogloss:0.12658\teval-mlogloss:0.20869\n",
      "[213]\ttrain-mlogloss:0.12632\teval-mlogloss:0.20867\n",
      "[214]\ttrain-mlogloss:0.12605\teval-mlogloss:0.20870\n",
      "[215]\ttrain-mlogloss:0.12564\teval-mlogloss:0.20881\n",
      "[216]\ttrain-mlogloss:0.12536\teval-mlogloss:0.20902\n",
      "[217]\ttrain-mlogloss:0.12501\teval-mlogloss:0.20904\n",
      "[218]\ttrain-mlogloss:0.12467\teval-mlogloss:0.20911\n",
      "[219]\ttrain-mlogloss:0.12430\teval-mlogloss:0.20925\n",
      "[220]\ttrain-mlogloss:0.12398\teval-mlogloss:0.20941\n",
      "[221]\ttrain-mlogloss:0.12365\teval-mlogloss:0.20952\n",
      "[222]\ttrain-mlogloss:0.12325\teval-mlogloss:0.20967\n",
      "[223]\ttrain-mlogloss:0.12277\teval-mlogloss:0.20991\n",
      "[224]\ttrain-mlogloss:0.12234\teval-mlogloss:0.21014\n",
      "[225]\ttrain-mlogloss:0.12210\teval-mlogloss:0.21030\n",
      "[226]\ttrain-mlogloss:0.12167\teval-mlogloss:0.21038\n",
      "[227]\ttrain-mlogloss:0.12138\teval-mlogloss:0.21049\n",
      "[228]\ttrain-mlogloss:0.12102\teval-mlogloss:0.21060\n",
      "[229]\ttrain-mlogloss:0.12058\teval-mlogloss:0.21058\n",
      "[230]\ttrain-mlogloss:0.12032\teval-mlogloss:0.21054\n",
      "[231]\ttrain-mlogloss:0.12003\teval-mlogloss:0.21057\n",
      "[232]\ttrain-mlogloss:0.11973\teval-mlogloss:0.21076\n",
      "[233]\ttrain-mlogloss:0.11944\teval-mlogloss:0.21063\n",
      "[234]\ttrain-mlogloss:0.11911\teval-mlogloss:0.21085\n",
      "[235]\ttrain-mlogloss:0.11882\teval-mlogloss:0.21105\n",
      "[236]\ttrain-mlogloss:0.11851\teval-mlogloss:0.21086\n",
      "[237]\ttrain-mlogloss:0.11821\teval-mlogloss:0.21076\n",
      "[238]\ttrain-mlogloss:0.11782\teval-mlogloss:0.21088\n",
      "[239]\ttrain-mlogloss:0.11756\teval-mlogloss:0.21102\n",
      "[240]\ttrain-mlogloss:0.11722\teval-mlogloss:0.21107\n",
      "Stopping. Best iteration:\n",
      "[140]\ttrain-mlogloss:0.16184\teval-mlogloss:0.20542\n",
      "\n",
      "xgb now score is: [2.4266696114931254, 2.207174352668226, 2.4680812854133545, 2.6257597387209533]\n",
      "[0]\ttrain-mlogloss:0.67111\teval-mlogloss:0.67067\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.65048\teval-mlogloss:0.64990\n",
      "[2]\ttrain-mlogloss:0.63095\teval-mlogloss:0.63042\n",
      "[3]\ttrain-mlogloss:0.61221\teval-mlogloss:0.61156\n",
      "[4]\ttrain-mlogloss:0.59425\teval-mlogloss:0.59358\n",
      "[5]\ttrain-mlogloss:0.57756\teval-mlogloss:0.57685\n",
      "[6]\ttrain-mlogloss:0.56168\teval-mlogloss:0.56063\n",
      "[7]\ttrain-mlogloss:0.54646\teval-mlogloss:0.54541\n",
      "[8]\ttrain-mlogloss:0.53202\teval-mlogloss:0.53083\n",
      "[9]\ttrain-mlogloss:0.51834\teval-mlogloss:0.51744\n",
      "[10]\ttrain-mlogloss:0.50532\teval-mlogloss:0.50439\n",
      "[11]\ttrain-mlogloss:0.49319\teval-mlogloss:0.49200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-mlogloss:0.48161\teval-mlogloss:0.48024\n",
      "[13]\ttrain-mlogloss:0.47056\teval-mlogloss:0.46910\n",
      "[14]\ttrain-mlogloss:0.45989\teval-mlogloss:0.45821\n",
      "[15]\ttrain-mlogloss:0.44969\teval-mlogloss:0.44814\n",
      "[16]\ttrain-mlogloss:0.43988\teval-mlogloss:0.43837\n",
      "[17]\ttrain-mlogloss:0.43052\teval-mlogloss:0.42910\n",
      "[18]\ttrain-mlogloss:0.42156\teval-mlogloss:0.42020\n",
      "[19]\ttrain-mlogloss:0.41305\teval-mlogloss:0.41174\n",
      "[20]\ttrain-mlogloss:0.40485\teval-mlogloss:0.40373\n",
      "[21]\ttrain-mlogloss:0.39698\teval-mlogloss:0.39576\n",
      "[22]\ttrain-mlogloss:0.38947\teval-mlogloss:0.38809\n",
      "[23]\ttrain-mlogloss:0.38232\teval-mlogloss:0.38081\n",
      "[24]\ttrain-mlogloss:0.37543\teval-mlogloss:0.37406\n",
      "[25]\ttrain-mlogloss:0.36868\teval-mlogloss:0.36762\n",
      "[26]\ttrain-mlogloss:0.36239\teval-mlogloss:0.36141\n",
      "[27]\ttrain-mlogloss:0.35632\teval-mlogloss:0.35523\n",
      "[28]\ttrain-mlogloss:0.35045\teval-mlogloss:0.34968\n",
      "[29]\ttrain-mlogloss:0.34489\teval-mlogloss:0.34417\n",
      "[30]\ttrain-mlogloss:0.33956\teval-mlogloss:0.33891\n",
      "[31]\ttrain-mlogloss:0.33441\teval-mlogloss:0.33369\n",
      "[32]\ttrain-mlogloss:0.32957\teval-mlogloss:0.32898\n",
      "[33]\ttrain-mlogloss:0.32460\teval-mlogloss:0.32413\n",
      "[34]\ttrain-mlogloss:0.32019\teval-mlogloss:0.31986\n",
      "[35]\ttrain-mlogloss:0.31572\teval-mlogloss:0.31564\n",
      "[36]\ttrain-mlogloss:0.31143\teval-mlogloss:0.31135\n",
      "[37]\ttrain-mlogloss:0.30725\teval-mlogloss:0.30738\n",
      "[38]\ttrain-mlogloss:0.30339\teval-mlogloss:0.30367\n",
      "[39]\ttrain-mlogloss:0.29962\teval-mlogloss:0.29998\n",
      "[40]\ttrain-mlogloss:0.29599\teval-mlogloss:0.29649\n",
      "[41]\ttrain-mlogloss:0.29249\teval-mlogloss:0.29308\n",
      "[42]\ttrain-mlogloss:0.28923\teval-mlogloss:0.28996\n",
      "[43]\ttrain-mlogloss:0.28600\teval-mlogloss:0.28692\n",
      "[44]\ttrain-mlogloss:0.28299\teval-mlogloss:0.28410\n",
      "[45]\ttrain-mlogloss:0.27995\teval-mlogloss:0.28107\n",
      "[46]\ttrain-mlogloss:0.27699\teval-mlogloss:0.27829\n",
      "[47]\ttrain-mlogloss:0.27398\teval-mlogloss:0.27548\n",
      "[48]\ttrain-mlogloss:0.27138\teval-mlogloss:0.27313\n",
      "[49]\ttrain-mlogloss:0.26888\teval-mlogloss:0.27070\n",
      "[50]\ttrain-mlogloss:0.26626\teval-mlogloss:0.26821\n",
      "[51]\ttrain-mlogloss:0.26385\teval-mlogloss:0.26598\n",
      "[52]\ttrain-mlogloss:0.26151\teval-mlogloss:0.26408\n",
      "[53]\ttrain-mlogloss:0.25934\teval-mlogloss:0.26202\n",
      "[54]\ttrain-mlogloss:0.25704\teval-mlogloss:0.26024\n",
      "[55]\ttrain-mlogloss:0.25497\teval-mlogloss:0.25836\n",
      "[56]\ttrain-mlogloss:0.25276\teval-mlogloss:0.25642\n",
      "[57]\ttrain-mlogloss:0.25063\teval-mlogloss:0.25428\n",
      "[58]\ttrain-mlogloss:0.24876\teval-mlogloss:0.25260\n",
      "[59]\ttrain-mlogloss:0.24685\teval-mlogloss:0.25105\n",
      "[60]\ttrain-mlogloss:0.24484\teval-mlogloss:0.24976\n",
      "[61]\ttrain-mlogloss:0.24291\teval-mlogloss:0.24838\n",
      "[62]\ttrain-mlogloss:0.24107\teval-mlogloss:0.24704\n",
      "[63]\ttrain-mlogloss:0.23938\teval-mlogloss:0.24563\n",
      "[64]\ttrain-mlogloss:0.23755\teval-mlogloss:0.24437\n",
      "[65]\ttrain-mlogloss:0.23586\teval-mlogloss:0.24311\n",
      "[66]\ttrain-mlogloss:0.23435\teval-mlogloss:0.24183\n",
      "[67]\ttrain-mlogloss:0.23305\teval-mlogloss:0.24045\n",
      "[68]\ttrain-mlogloss:0.23169\teval-mlogloss:0.23946\n",
      "[69]\ttrain-mlogloss:0.22996\teval-mlogloss:0.23843\n",
      "[70]\ttrain-mlogloss:0.22825\teval-mlogloss:0.23746\n",
      "[71]\ttrain-mlogloss:0.22673\teval-mlogloss:0.23646\n",
      "[72]\ttrain-mlogloss:0.22556\teval-mlogloss:0.23572\n",
      "[73]\ttrain-mlogloss:0.22408\teval-mlogloss:0.23481\n",
      "[74]\ttrain-mlogloss:0.22278\teval-mlogloss:0.23409\n",
      "[75]\ttrain-mlogloss:0.22134\teval-mlogloss:0.23320\n",
      "[76]\ttrain-mlogloss:0.21987\teval-mlogloss:0.23254\n",
      "[77]\ttrain-mlogloss:0.21856\teval-mlogloss:0.23191\n",
      "[78]\ttrain-mlogloss:0.21725\teval-mlogloss:0.23119\n",
      "[79]\ttrain-mlogloss:0.21587\teval-mlogloss:0.23033\n",
      "[80]\ttrain-mlogloss:0.21450\teval-mlogloss:0.22981\n",
      "[81]\ttrain-mlogloss:0.21318\teval-mlogloss:0.22925\n",
      "[82]\ttrain-mlogloss:0.21183\teval-mlogloss:0.22837\n",
      "[83]\ttrain-mlogloss:0.21071\teval-mlogloss:0.22782\n",
      "[84]\ttrain-mlogloss:0.20941\teval-mlogloss:0.22710\n",
      "[85]\ttrain-mlogloss:0.20823\teval-mlogloss:0.22673\n",
      "[86]\ttrain-mlogloss:0.20705\teval-mlogloss:0.22627\n",
      "[87]\ttrain-mlogloss:0.20593\teval-mlogloss:0.22559\n",
      "[88]\ttrain-mlogloss:0.20478\teval-mlogloss:0.22521\n",
      "[89]\ttrain-mlogloss:0.20358\teval-mlogloss:0.22479\n",
      "[90]\ttrain-mlogloss:0.20256\teval-mlogloss:0.22448\n",
      "[91]\ttrain-mlogloss:0.20147\teval-mlogloss:0.22413\n",
      "[92]\ttrain-mlogloss:0.20030\teval-mlogloss:0.22346\n",
      "[93]\ttrain-mlogloss:0.19926\teval-mlogloss:0.22288\n",
      "[94]\ttrain-mlogloss:0.19829\teval-mlogloss:0.22271\n",
      "[95]\ttrain-mlogloss:0.19728\teval-mlogloss:0.22210\n",
      "[96]\ttrain-mlogloss:0.19627\teval-mlogloss:0.22180\n",
      "[97]\ttrain-mlogloss:0.19514\teval-mlogloss:0.22149\n",
      "[98]\ttrain-mlogloss:0.19413\teval-mlogloss:0.22129\n",
      "[99]\ttrain-mlogloss:0.19317\teval-mlogloss:0.22068\n",
      "[100]\ttrain-mlogloss:0.19224\teval-mlogloss:0.22047\n",
      "[101]\ttrain-mlogloss:0.19138\teval-mlogloss:0.22037\n",
      "[102]\ttrain-mlogloss:0.19045\teval-mlogloss:0.22037\n",
      "[103]\ttrain-mlogloss:0.18947\teval-mlogloss:0.22009\n",
      "[104]\ttrain-mlogloss:0.18853\teval-mlogloss:0.22008\n",
      "[105]\ttrain-mlogloss:0.18760\teval-mlogloss:0.21993\n",
      "[106]\ttrain-mlogloss:0.18673\teval-mlogloss:0.21943\n",
      "[107]\ttrain-mlogloss:0.18574\teval-mlogloss:0.21933\n",
      "[108]\ttrain-mlogloss:0.18475\teval-mlogloss:0.21912\n",
      "[109]\ttrain-mlogloss:0.18380\teval-mlogloss:0.21891\n",
      "[110]\ttrain-mlogloss:0.18292\teval-mlogloss:0.21883\n",
      "[111]\ttrain-mlogloss:0.18199\teval-mlogloss:0.21859\n",
      "[112]\ttrain-mlogloss:0.18101\teval-mlogloss:0.21859\n",
      "[113]\ttrain-mlogloss:0.18008\teval-mlogloss:0.21845\n",
      "[114]\ttrain-mlogloss:0.17930\teval-mlogloss:0.21826\n",
      "[115]\ttrain-mlogloss:0.17852\teval-mlogloss:0.21828\n",
      "[116]\ttrain-mlogloss:0.17763\teval-mlogloss:0.21809\n",
      "[117]\ttrain-mlogloss:0.17697\teval-mlogloss:0.21815\n",
      "[118]\ttrain-mlogloss:0.17617\teval-mlogloss:0.21795\n",
      "[119]\ttrain-mlogloss:0.17549\teval-mlogloss:0.21783\n",
      "[120]\ttrain-mlogloss:0.17458\teval-mlogloss:0.21769\n",
      "[121]\ttrain-mlogloss:0.17391\teval-mlogloss:0.21754\n",
      "[122]\ttrain-mlogloss:0.17311\teval-mlogloss:0.21764\n",
      "[123]\ttrain-mlogloss:0.17224\teval-mlogloss:0.21762\n",
      "[124]\ttrain-mlogloss:0.17147\teval-mlogloss:0.21781\n",
      "[125]\ttrain-mlogloss:0.17075\teval-mlogloss:0.21746\n",
      "[126]\ttrain-mlogloss:0.16996\teval-mlogloss:0.21771\n",
      "[127]\ttrain-mlogloss:0.16922\teval-mlogloss:0.21746\n",
      "[128]\ttrain-mlogloss:0.16844\teval-mlogloss:0.21748\n",
      "[129]\ttrain-mlogloss:0.16771\teval-mlogloss:0.21768\n",
      "[130]\ttrain-mlogloss:0.16715\teval-mlogloss:0.21786\n",
      "[131]\ttrain-mlogloss:0.16637\teval-mlogloss:0.21785\n",
      "[132]\ttrain-mlogloss:0.16564\teval-mlogloss:0.21793\n",
      "[133]\ttrain-mlogloss:0.16487\teval-mlogloss:0.21788\n",
      "[134]\ttrain-mlogloss:0.16419\teval-mlogloss:0.21779\n",
      "[135]\ttrain-mlogloss:0.16350\teval-mlogloss:0.21752\n",
      "[136]\ttrain-mlogloss:0.16270\teval-mlogloss:0.21757\n",
      "[137]\ttrain-mlogloss:0.16199\teval-mlogloss:0.21749\n",
      "[138]\ttrain-mlogloss:0.16139\teval-mlogloss:0.21760\n",
      "[139]\ttrain-mlogloss:0.16071\teval-mlogloss:0.21743\n",
      "[140]\ttrain-mlogloss:0.16003\teval-mlogloss:0.21738\n",
      "[141]\ttrain-mlogloss:0.15945\teval-mlogloss:0.21722\n",
      "[142]\ttrain-mlogloss:0.15877\teval-mlogloss:0.21724\n",
      "[143]\ttrain-mlogloss:0.15814\teval-mlogloss:0.21717\n",
      "[144]\ttrain-mlogloss:0.15746\teval-mlogloss:0.21706\n",
      "[145]\ttrain-mlogloss:0.15687\teval-mlogloss:0.21729\n",
      "[146]\ttrain-mlogloss:0.15617\teval-mlogloss:0.21745\n",
      "[147]\ttrain-mlogloss:0.15559\teval-mlogloss:0.21749\n",
      "[148]\ttrain-mlogloss:0.15497\teval-mlogloss:0.21749\n",
      "[149]\ttrain-mlogloss:0.15456\teval-mlogloss:0.21746\n",
      "[150]\ttrain-mlogloss:0.15395\teval-mlogloss:0.21760\n",
      "[151]\ttrain-mlogloss:0.15354\teval-mlogloss:0.21772\n",
      "[152]\ttrain-mlogloss:0.15299\teval-mlogloss:0.21775\n",
      "[153]\ttrain-mlogloss:0.15230\teval-mlogloss:0.21754\n",
      "[154]\ttrain-mlogloss:0.15171\teval-mlogloss:0.21764\n",
      "[155]\ttrain-mlogloss:0.15113\teval-mlogloss:0.21761\n",
      "[156]\ttrain-mlogloss:0.15068\teval-mlogloss:0.21771\n",
      "[157]\ttrain-mlogloss:0.15023\teval-mlogloss:0.21771\n",
      "[158]\ttrain-mlogloss:0.14955\teval-mlogloss:0.21765\n",
      "[159]\ttrain-mlogloss:0.14893\teval-mlogloss:0.21757\n",
      "[160]\ttrain-mlogloss:0.14837\teval-mlogloss:0.21741\n",
      "[161]\ttrain-mlogloss:0.14781\teval-mlogloss:0.21740\n",
      "[162]\ttrain-mlogloss:0.14723\teval-mlogloss:0.21743\n",
      "[163]\ttrain-mlogloss:0.14673\teval-mlogloss:0.21768\n",
      "[164]\ttrain-mlogloss:0.14611\teval-mlogloss:0.21770\n",
      "[165]\ttrain-mlogloss:0.14555\teval-mlogloss:0.21766\n",
      "[166]\ttrain-mlogloss:0.14499\teval-mlogloss:0.21777\n",
      "[167]\ttrain-mlogloss:0.14454\teval-mlogloss:0.21747\n",
      "[168]\ttrain-mlogloss:0.14400\teval-mlogloss:0.21742\n",
      "[169]\ttrain-mlogloss:0.14358\teval-mlogloss:0.21739\n",
      "[170]\ttrain-mlogloss:0.14301\teval-mlogloss:0.21743\n",
      "[171]\ttrain-mlogloss:0.14254\teval-mlogloss:0.21755\n",
      "[172]\ttrain-mlogloss:0.14196\teval-mlogloss:0.21739\n",
      "[173]\ttrain-mlogloss:0.14149\teval-mlogloss:0.21741\n",
      "[174]\ttrain-mlogloss:0.14097\teval-mlogloss:0.21749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]\ttrain-mlogloss:0.14060\teval-mlogloss:0.21745\n",
      "[176]\ttrain-mlogloss:0.14017\teval-mlogloss:0.21770\n",
      "[177]\ttrain-mlogloss:0.13973\teval-mlogloss:0.21778\n",
      "[178]\ttrain-mlogloss:0.13938\teval-mlogloss:0.21789\n",
      "[179]\ttrain-mlogloss:0.13902\teval-mlogloss:0.21808\n",
      "[180]\ttrain-mlogloss:0.13846\teval-mlogloss:0.21802\n",
      "[181]\ttrain-mlogloss:0.13795\teval-mlogloss:0.21814\n",
      "[182]\ttrain-mlogloss:0.13750\teval-mlogloss:0.21828\n",
      "[183]\ttrain-mlogloss:0.13699\teval-mlogloss:0.21859\n",
      "[184]\ttrain-mlogloss:0.13654\teval-mlogloss:0.21859\n",
      "[185]\ttrain-mlogloss:0.13600\teval-mlogloss:0.21843\n",
      "[186]\ttrain-mlogloss:0.13551\teval-mlogloss:0.21854\n",
      "[187]\ttrain-mlogloss:0.13511\teval-mlogloss:0.21848\n",
      "[188]\ttrain-mlogloss:0.13462\teval-mlogloss:0.21846\n",
      "[189]\ttrain-mlogloss:0.13429\teval-mlogloss:0.21849\n",
      "[190]\ttrain-mlogloss:0.13391\teval-mlogloss:0.21851\n",
      "[191]\ttrain-mlogloss:0.13350\teval-mlogloss:0.21853\n",
      "[192]\ttrain-mlogloss:0.13309\teval-mlogloss:0.21847\n",
      "[193]\ttrain-mlogloss:0.13275\teval-mlogloss:0.21842\n",
      "[194]\ttrain-mlogloss:0.13237\teval-mlogloss:0.21849\n",
      "[195]\ttrain-mlogloss:0.13190\teval-mlogloss:0.21861\n",
      "[196]\ttrain-mlogloss:0.13144\teval-mlogloss:0.21868\n",
      "[197]\ttrain-mlogloss:0.13107\teval-mlogloss:0.21867\n",
      "[198]\ttrain-mlogloss:0.13065\teval-mlogloss:0.21849\n",
      "[199]\ttrain-mlogloss:0.13018\teval-mlogloss:0.21836\n",
      "[200]\ttrain-mlogloss:0.12975\teval-mlogloss:0.21835\n",
      "[201]\ttrain-mlogloss:0.12929\teval-mlogloss:0.21836\n",
      "[202]\ttrain-mlogloss:0.12893\teval-mlogloss:0.21834\n",
      "[203]\ttrain-mlogloss:0.12852\teval-mlogloss:0.21828\n",
      "[204]\ttrain-mlogloss:0.12823\teval-mlogloss:0.21832\n",
      "[205]\ttrain-mlogloss:0.12787\teval-mlogloss:0.21849\n",
      "[206]\ttrain-mlogloss:0.12754\teval-mlogloss:0.21837\n",
      "[207]\ttrain-mlogloss:0.12709\teval-mlogloss:0.21852\n",
      "[208]\ttrain-mlogloss:0.12680\teval-mlogloss:0.21872\n",
      "[209]\ttrain-mlogloss:0.12636\teval-mlogloss:0.21895\n",
      "[210]\ttrain-mlogloss:0.12599\teval-mlogloss:0.21922\n",
      "[211]\ttrain-mlogloss:0.12557\teval-mlogloss:0.21947\n",
      "[212]\ttrain-mlogloss:0.12529\teval-mlogloss:0.21960\n",
      "[213]\ttrain-mlogloss:0.12496\teval-mlogloss:0.21961\n",
      "[214]\ttrain-mlogloss:0.12466\teval-mlogloss:0.21985\n",
      "[215]\ttrain-mlogloss:0.12429\teval-mlogloss:0.21999\n",
      "[216]\ttrain-mlogloss:0.12394\teval-mlogloss:0.21995\n",
      "[217]\ttrain-mlogloss:0.12364\teval-mlogloss:0.21998\n",
      "[218]\ttrain-mlogloss:0.12334\teval-mlogloss:0.22029\n",
      "[219]\ttrain-mlogloss:0.12300\teval-mlogloss:0.22046\n",
      "[220]\ttrain-mlogloss:0.12268\teval-mlogloss:0.22073\n",
      "[221]\ttrain-mlogloss:0.12238\teval-mlogloss:0.22081\n",
      "[222]\ttrain-mlogloss:0.12205\teval-mlogloss:0.22087\n",
      "[223]\ttrain-mlogloss:0.12175\teval-mlogloss:0.22095\n",
      "[224]\ttrain-mlogloss:0.12143\teval-mlogloss:0.22092\n",
      "[225]\ttrain-mlogloss:0.12112\teval-mlogloss:0.22089\n",
      "[226]\ttrain-mlogloss:0.12081\teval-mlogloss:0.22098\n",
      "[227]\ttrain-mlogloss:0.12044\teval-mlogloss:0.22111\n",
      "[228]\ttrain-mlogloss:0.12020\teval-mlogloss:0.22115\n",
      "[229]\ttrain-mlogloss:0.11991\teval-mlogloss:0.22112\n",
      "[230]\ttrain-mlogloss:0.11951\teval-mlogloss:0.22102\n",
      "[231]\ttrain-mlogloss:0.11917\teval-mlogloss:0.22111\n",
      "[232]\ttrain-mlogloss:0.11894\teval-mlogloss:0.22105\n",
      "[233]\ttrain-mlogloss:0.11868\teval-mlogloss:0.22121\n",
      "[234]\ttrain-mlogloss:0.11847\teval-mlogloss:0.22121\n",
      "[235]\ttrain-mlogloss:0.11814\teval-mlogloss:0.22110\n",
      "[236]\ttrain-mlogloss:0.11783\teval-mlogloss:0.22107\n",
      "[237]\ttrain-mlogloss:0.11753\teval-mlogloss:0.22124\n",
      "[238]\ttrain-mlogloss:0.11729\teval-mlogloss:0.22152\n",
      "[239]\ttrain-mlogloss:0.11707\teval-mlogloss:0.22163\n",
      "[240]\ttrain-mlogloss:0.11669\teval-mlogloss:0.22162\n",
      "[241]\ttrain-mlogloss:0.11638\teval-mlogloss:0.22176\n",
      "[242]\ttrain-mlogloss:0.11613\teval-mlogloss:0.22188\n",
      "[243]\ttrain-mlogloss:0.11585\teval-mlogloss:0.22179\n",
      "[244]\ttrain-mlogloss:0.11557\teval-mlogloss:0.22170\n",
      "Stopping. Best iteration:\n",
      "[144]\ttrain-mlogloss:0.15746\teval-mlogloss:0.21706\n",
      "\n",
      "xgb now score is: [2.4266696114931254, 2.207174352668226, 2.4680812854133545, 2.6257597387209533, 2.6945626328326764]\n",
      "xgb_score_list: [2.4266696114931254, 2.207174352668226, 2.4680812854133545, 2.6257597387209533, 2.6945626328326764]\n",
      "xgb_score_mean: 2.484449524225667\n"
     ]
    }
   ],
   "source": [
    "clf_list = clf_list\n",
    "column_list = []\n",
    "train_data_list=[]\n",
    "test_data_list=[]\n",
    "for clf in clf_list:\n",
    "    train_data,test_data,clf_name=clf(x_train, y_train, x_valid, kf, label_split=None)\n",
    "    train_data_list.append(train_data)\n",
    "    test_data_list.append(test_data)\n",
    "train_stacking = np.concatenate(train_data_list, axis=1)\n",
    "test_stacking = np.concatenate(test_data_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始特征和stacking特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 合并所有特征\n",
    "train = pd.DataFrame(np.concatenate([x_train, train_stacking], axis=1))\n",
    "test = np.concatenate([x_valid, test_stacking], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 230), (2000, 230), (2000, 2))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape,train_stacking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 236)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, ['lgb_clf', 'xgb_clf'], 230)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_columns),clf_list_col,len(features_columns + clf_list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = pd.DataFrame(train)\n",
    "df_train_all.columns = features_columns + clf_list_col\n",
    "df_test_all = pd.DataFrame(test)\n",
    "df_test_all.columns = features_columns + clf_list_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据ID以及特征标签LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['user_id'] = all_data_test[~all_data_test['label'].isna()]['user_id']\n",
    "df_test_all['user_id'] = all_data_test[all_data_test['label'].isna()]['user_id']\n",
    "df_train_all['label'] = all_data_test[~all_data_test['label'].isna()]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_path</th>\n",
       "      <th>cat_path</th>\n",
       "      <th>seller_path</th>\n",
       "      <th>brand_path</th>\n",
       "      <th>...</th>\n",
       "      <th>embeeding_90</th>\n",
       "      <th>embeeding_91</th>\n",
       "      <th>embeeding_92</th>\n",
       "      <th>embeeding_93</th>\n",
       "      <th>embeeding_94</th>\n",
       "      <th>embeeding_95</th>\n",
       "      <th>embeeding_96</th>\n",
       "      <th>embeeding_97</th>\n",
       "      <th>embeeding_98</th>\n",
       "      <th>embeeding_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, merchant_id, label, prob, age_range, gender, item_path, cat_path, seller_path, brand_path, time_stamp_path, action_type_path, user_cnt, seller_nunique, cat_nunique, brand_nunique, item_nunique, time_stamp_nunique, action_type_nunique, time_stamp_max, time_stamp_min, time_stamp_std, time_stamp_range, seller_most_1, cat_most_1, brand_most_1, action_type_1, seller_most_1_cnt, cat_most_1_cnt, brand_most_1_cnt, action_type_1_cnt, user_cnt_0, user_cnt_1, user_cnt_2, user_cnt_3, seller_nunique_0, tfidf_0, tfidf_1, tfidf_2, tfidf_3, tfidf_4, tfidf_5, tfidf_6, tfidf_7, tfidf_8, tfidf_9, tfidf_10, tfidf_11, tfidf_12, tfidf_13, tfidf_14, tfidf_15, tfidf_16, tfidf_17, tfidf_18, tfidf_19, tfidf_20, tfidf_21, tfidf_22, tfidf_23, tfidf_24, tfidf_25, tfidf_26, tfidf_27, tfidf_28, tfidf_29, tfidf_30, tfidf_31, tfidf_32, tfidf_33, tfidf_34, tfidf_35, tfidf_36, tfidf_37, tfidf_38, tfidf_39, tfidf_40, tfidf_41, tfidf_42, tfidf_43, tfidf_44, tfidf_45, tfidf_46, tfidf_47, tfidf_48, tfidf_49, tfidf_50, tfidf_51, tfidf_52, tfidf_53, tfidf_54, tfidf_55, tfidf_56, tfidf_57, tfidf_58, tfidf_59, tfidf_60, tfidf_61, tfidf_62, tfidf_63, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 236 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_test[all_data_test['label'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据和测试数据保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all.to_csv('train_all.csv',header=True,index=False)\n",
    "df_test_all.to_csv('test_all.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
